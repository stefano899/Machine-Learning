{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:21:21.171499Z",
     "start_time": "2025-08-06T16:21:21.168087Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.src.metrics import BinaryAccuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T15:16:51.651969Z",
     "start_time": "2025-08-06T15:16:51.650211Z"
    }
   },
   "id": "51e4a04fe5af6859",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      letter  x-box  y-box  width  high  onpix  x-bar  y-bar  x2bar  y2bar  \\\n0          T      2      8      3     5      1      8     13      0      6   \n1          I      5     12      3     7      2     10      5      5      4   \n2          D      4     11      6     8      6     10      6      2      6   \n3          N      7     11      6     6      3      5      9      4      6   \n4          G      2      1      3     1      1      8      6      6      6   \n...      ...    ...    ...    ...   ...    ...    ...    ...    ...    ...   \n19995      D      2      2      3     3      2      7      7      7      6   \n19996      C      7     10      8     8      4      4      8      6      9   \n19997      T      6      9      6     7      5      6     11      3      7   \n19998      S      2      3      4     2      1      8      7      2      6   \n19999      A      4      9      6     6      2      9      5      3      1   \n\n       xybar  x2ybr  xy2br  x-ege  xegvy  y-ege  yegvx  \n0          6     10      8      0      8      0      8  \n1         13      3      9      2      8      4     10  \n2         10      3      7      3      7      3      9  \n3          4      4     10      6     10      2      8  \n4          6      5      9      1      7      5     10  \n...      ...    ...    ...    ...    ...    ...    ...  \n19995      6      6      4      2      8      3      7  \n19996     12      9     13      2      9      3      7  \n19997     11      9      5      2     12      2      4  \n19998     10      6      8      1      9      5      8  \n19999      8      1      8      2      7      2      8  \n\n[20000 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>letter</th>\n      <th>x-box</th>\n      <th>y-box</th>\n      <th>width</th>\n      <th>high</th>\n      <th>onpix</th>\n      <th>x-bar</th>\n      <th>y-bar</th>\n      <th>x2bar</th>\n      <th>y2bar</th>\n      <th>xybar</th>\n      <th>x2ybr</th>\n      <th>xy2br</th>\n      <th>x-ege</th>\n      <th>xegvy</th>\n      <th>y-ege</th>\n      <th>yegvx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>T</td>\n      <td>2</td>\n      <td>8</td>\n      <td>3</td>\n      <td>5</td>\n      <td>1</td>\n      <td>8</td>\n      <td>13</td>\n      <td>0</td>\n      <td>6</td>\n      <td>6</td>\n      <td>10</td>\n      <td>8</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I</td>\n      <td>5</td>\n      <td>12</td>\n      <td>3</td>\n      <td>7</td>\n      <td>2</td>\n      <td>10</td>\n      <td>5</td>\n      <td>5</td>\n      <td>4</td>\n      <td>13</td>\n      <td>3</td>\n      <td>9</td>\n      <td>2</td>\n      <td>8</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>D</td>\n      <td>4</td>\n      <td>11</td>\n      <td>6</td>\n      <td>8</td>\n      <td>6</td>\n      <td>10</td>\n      <td>6</td>\n      <td>2</td>\n      <td>6</td>\n      <td>10</td>\n      <td>3</td>\n      <td>7</td>\n      <td>3</td>\n      <td>7</td>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>N</td>\n      <td>7</td>\n      <td>11</td>\n      <td>6</td>\n      <td>6</td>\n      <td>3</td>\n      <td>5</td>\n      <td>9</td>\n      <td>4</td>\n      <td>6</td>\n      <td>4</td>\n      <td>4</td>\n      <td>10</td>\n      <td>6</td>\n      <td>10</td>\n      <td>2</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>G</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>5</td>\n      <td>9</td>\n      <td>1</td>\n      <td>7</td>\n      <td>5</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>D</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>4</td>\n      <td>2</td>\n      <td>8</td>\n      <td>3</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>C</td>\n      <td>7</td>\n      <td>10</td>\n      <td>8</td>\n      <td>8</td>\n      <td>4</td>\n      <td>4</td>\n      <td>8</td>\n      <td>6</td>\n      <td>9</td>\n      <td>12</td>\n      <td>9</td>\n      <td>13</td>\n      <td>2</td>\n      <td>9</td>\n      <td>3</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>T</td>\n      <td>6</td>\n      <td>9</td>\n      <td>6</td>\n      <td>7</td>\n      <td>5</td>\n      <td>6</td>\n      <td>11</td>\n      <td>3</td>\n      <td>7</td>\n      <td>11</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2</td>\n      <td>12</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>S</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>8</td>\n      <td>7</td>\n      <td>2</td>\n      <td>6</td>\n      <td>10</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1</td>\n      <td>9</td>\n      <td>5</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>A</td>\n      <td>4</td>\n      <td>9</td>\n      <td>6</td>\n      <td>6</td>\n      <td>2</td>\n      <td>9</td>\n      <td>5</td>\n      <td>3</td>\n      <td>1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>8</td>\n      <td>2</td>\n      <td>7</td>\n      <td>2</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>20000 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaiming columns\n",
    "columns = ['letter', 'x-box', 'y-box', 'width', 'high', 'onpix', \n",
    "              'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', \n",
    "              'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx']\n",
    "\n",
    "df = pd.read_csv(\"letter-recognition.data\", header=None, names=columns)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T15:16:53.552926Z",
     "start_time": "2025-08-06T15:16:53.518405Z"
    }
   },
   "id": "615052c052cf5c",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One-Hot encoding "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c0e098516ea6de"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "df_encoded = encoder.fit_transform(df).toarray()\n",
    "df_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T15:16:55.600444Z",
     "start_time": "2025-08-06T15:16:55.559406Z"
    }
   },
   "id": "d523fe5f2924d144",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def build_indices(df, columns):\n",
    "    indices = {}\n",
    "    prev = 0\n",
    "    for i in range(len(columns)):\n",
    "        if i == 0:\n",
    "            succ = len(df[columns[i]].unique())\n",
    "            indices[i] = range(prev, succ)\n",
    "        else:\n",
    "            succ = prev + len(df[columns[i]].unique())\n",
    "            indices[i] = range(prev, succ)\n",
    "        prev = succ\n",
    "    return indices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T15:16:56.788880Z",
     "start_time": "2025-08-06T15:16:56.784160Z"
    }
   },
   "id": "6a0eaa7d1286807c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{0: range(0, 26),\n 1: range(26, 42),\n 2: range(42, 58),\n 3: range(58, 74),\n 4: range(74, 90),\n 5: range(90, 106),\n 6: range(106, 122),\n 7: range(122, 138),\n 8: range(138, 154),\n 9: range(154, 170),\n 10: range(170, 186),\n 11: range(186, 202),\n 12: range(202, 218),\n 13: range(218, 234),\n 14: range(234, 250),\n 15: range(250, 266),\n 16: range(266, 282)}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "indices = {\n",
    "    0: range(0, 26), # letters\n",
    "    1: range(26, 42), # x-box\n",
    "    2: range(42, 58), # y-box\n",
    "    3: range(58, 74), # width\n",
    "    4: range(74, 90), # high\n",
    "    5: range(90, 106), # on-pix\n",
    "    6: range(106, 122), # x-bar\n",
    "    7: range(122, 138), # y-bar\n",
    "    8: range(138, 154), # x2bar\n",
    "    9: range(154, 170), # y2bar\n",
    "    10: range(170, 186), # xybar\n",
    "    11: range(186, 202), #x2ybr\n",
    "    12: range(202, 218), # xy2br\n",
    "    13: range(218, 234), # x-ege\n",
    "    14: range(234, 250), # xegvy\n",
    "    15: range(250, 266), # y-ege\n",
    "    16: range(266, 282) # yegvx\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "indices = build_indices(df, columns)\n",
    "indices\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T15:16:59.518407Z",
     "start_time": "2025-08-06T15:16:59.512619Z"
    }
   },
   "id": "9af31adedbd03e17",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I'm going to simulate missing values from the dataset\n",
    "### I'm going to randomly set some values to 0 in every row\n",
    "### The original dataset will be set as Target"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fa5a520d61d5a99"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def adding_missing_values(data, indices, k, m):\n",
    "    X = data.copy()\n",
    "    numbers = list(indices.keys())  # list of symbolic variable indices\n",
    "    combinations = itertools.combinations(numbers, k)  # all possible combinations of k variables\n",
    "\n",
    "    for comb in combinations:\n",
    "        # Choose m random rows\n",
    "        rows = np.random.choice(X.shape[0], m, replace=False)\n",
    "   \n",
    "        \n",
    "        for col in comb:\n",
    "            column_indices = list(indices[col])\n",
    "            for j in column_indices:\n",
    "                X[rows, j] = 0.0\n",
    "\n",
    "    return X\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:04:54.429676Z",
     "start_time": "2025-08-06T16:04:54.426208Z"
    }
   },
   "id": "f750c87f498584e4",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected rows: [ 7126  7367 18356 11038 11909  9150 14514  3299 12442 15051  4732  1811\n",
      " 15108  9450  8984 14734 19721  5773 16039   440  1987 15592 19951   416\n",
      "  2232 12727  7897  7479  7922  3581 16917 10749  7564 14078 12046  7598\n",
      "   368  5222 19919  8203 15437  1295  1684 18827 15244 12780  6739  9378\n",
      " 16524 14370  2392  6633 14295  9697  5279 19871  3426 14230 18189 15566\n",
      "  1950 15614   663 19186 14710  2714  3409 11462 15026 14970  9489 14769\n",
      "  2561  9929  3618  3690  3701 10184 10309 15335 12898  6646  8989  1235\n",
      "  7571 16230  1506  9954 19406 15017  7524  1891 17028 13257 18892  2439\n",
      " 16565 18969  1215  7164]\n",
      "Selected symbolic variables (by index): (0,)\n",
      "Zeroing out columns [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25] (corresponding to variable 0)\n",
      "\n",
      "Selected rows: [ 4490 17671 18912 16629 15233 14538  6014  3525 17691  6740 10713 19908\n",
      " 13786 16711 11200  8276 17158  2171 11035  1394 18310 18579  3224  3532\n",
      " 18981 17820 13451 14822 11370    37  9759 16280 13821 16324  8118  3785\n",
      "  4030 12384 15465  7563  6688  3179  7435   946 12835 18058   594  6914\n",
      " 19583 16901  1047 18258  4449  4868 15157  5537 16442  7190  2009 19629\n",
      "  7630  1022 16053 10611 11642 15609 18265  1276 16091  2781   460 13673\n",
      " 11693  6675 10871  2964 10662 18375  2980 15713 14254 10920  5477  1146\n",
      "  6844  7817 15643 19023  3808  2746 17404  4309  4904  6424  9608  6608\n",
      " 17130 13708 17183  6955]\n",
      "Selected symbolic variables (by index): (1,)\n",
      "Zeroing out columns [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41] (corresponding to variable 1)\n",
      "\n",
      "Selected rows: [  675 15580  4502 15662 18456 17630   921  7455  3479  9640  6548 17492\n",
      " 11491 17147  2642  2276  1269 18469  3945  8939  7059 12906  4049  4482\n",
      " 16444  2815  3267 19513 14461 14594  8464  9876 13002 13762 16300 10068\n",
      "  8740  5679  5252 12163  3356  7640 15949 13289 17604  1832   368 12009\n",
      " 18261 17513  1914 15378  3418  9720 14023 17649   138 19990  4631 14567\n",
      " 14251 18084 14852 19049  3190 13202  4676  9475 10749 18309  4687 16121\n",
      " 13740 10473  6465 19411  7454 16842 11407  8045  4197 16863  2759 10356\n",
      " 12750 10680  5457  4541   289  4181  3529 12522 19145 13378  2169  6457\n",
      "  3870 13138 18363  7673]\n",
      "Selected symbolic variables (by index): (2,)\n",
      "Zeroing out columns [42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57] (corresponding to variable 2)\n",
      "\n",
      "Selected rows: [ 2636 14104   378  9404 15763  1179  2775  2286 16086  8231 17749  2432\n",
      "  3062 12585 13130   714 16221 15607 17649  8947  2990  1057   986 19655\n",
      " 13299  9088  5663  9755 13885 10112 18563 11833  9785  7929  7605 10842\n",
      " 11032 19389 11056  7596 11100 17469  3753  2896  9061   335  1757  2998\n",
      "  5235  3957 14314  2982 10947  9678 12221 13419  7269 14871   173 11652\n",
      "  8480  8229 18696 12764  5458 13677  1825 12624  4055 18316  3377   250\n",
      "  6787 10740  5318 11813  9059 19285 18645  4599 18213  2031   578  6052\n",
      "  3417  7680 13441  3320  3667  7330  1885 14241 17564  2823  5311 18579\n",
      "  4649 12395  2977  2483]\n",
      "Selected symbolic variables (by index): (3,)\n",
      "Zeroing out columns [58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73] (corresponding to variable 3)\n",
      "\n",
      "Selected rows: [ 7586  5167  5848  2609  4062 11495   500 10844  4556  3759  8968 12814\n",
      "  7376 14536  7938 12444  3731 13740 13941  9494 11578 14880  3331 14728\n",
      " 12068 16723  9358 10363  2618 19930  9021  8436  2196  2128  2238  6469\n",
      "  3777  8540 16779  4443  8871  8778 14390  5261 10741  9789  9011 12323\n",
      "  5121  8993  7974 15079 16627  2291 10743 18092 17938 18643  1504 17318\n",
      "    53  3040 14749  8335  5520 12106  3119 18444 14832 11930  1026  4037\n",
      "   814 10804  1454 12635  5819  9495 19913   395 17371 12786  4326 19391\n",
      " 18739 11635 18580    41  6484 13516  8193 10542 18992 12332 10300  4724\n",
      "  5972  2652  7540  8311]\n",
      "Selected symbolic variables (by index): (4,)\n",
      "Zeroing out columns [74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89] (corresponding to variable 4)\n",
      "\n",
      "Selected rows: [    2 19013 12497  2659 15770 10282 15539 12357  4551 17718  6952  4951\n",
      "  9164 16869 17839  4908 10986 19865 12793  2142 17847 16058   543 18220\n",
      " 19591  7943 14618 16025  2677 17816   235  8107  3941  4177  2259  5920\n",
      "  4237  3800 18251 12724  4058   183 19348 16664   146 15010 10350  6124\n",
      "  3784  2724 17459  9699  9617 13669  2305 12559  2116 14016 18162  5970\n",
      " 14162   903 18438 11250  8718 14157  9974  2282 11662 17091  6565  9734\n",
      "   509  6265  6314  7361 14600  5551 11116  2935  4900  3459 16055  8564\n",
      " 10592  1760 13018  6855 10652 19024  2410  7397 10773 18967 18976 18123\n",
      "  4318 18462   944 18728]\n",
      "Selected symbolic variables (by index): (5,)\n",
      "Zeroing out columns [90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105] (corresponding to variable 5)\n",
      "\n",
      "Selected rows: [15674 10967  3196 17859  6664 15349  9107 13474 17698 15237 10597  2522\n",
      " 19164 14307 13032 11419  7779 17141 16327  4065  1312  7379 15541  5374\n",
      "  8624  2386 13814  2535 16546 11544 14353  8398 17208 19933  4277  4429\n",
      "  6835  5616 16839  2578  8085  9702  2973 19973 17721  9144  1955  7722\n",
      " 16096 13863  6032 13600  8421  7004 17907  1139  2884  5278 14141 18612\n",
      " 11302  9870  8309 15502 12912    13 12846   756  5447 18897  7346  4967\n",
      "  7067  3937 19941 14812 17186   878  1470  7920  4195 19726 19596 12190\n",
      "  7939 14506 17749 19738 12328 10551  7398 12714   273 12765 15976 10911\n",
      "  6998  2583 11379 17939]\n",
      "Selected symbolic variables (by index): (6,)\n",
      "Zeroing out columns [106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121] (corresponding to variable 6)\n",
      "\n",
      "Selected rows: [11267  6761 13858 17827  3158  7311 12214  9024 19684 17108 13104  3150\n",
      " 14216  4071  6516  8059 10610 18141 16531 17152  8842   932   301  8701\n",
      "   247  1958  9339 16304 14503 16276  7915  7565  2975 18282 14961 11635\n",
      "  7084  1784 18450  9955  2094 19030 13380  7249  3082  6568  7061  5301\n",
      "   529  6979  1321 17689   583  1749  1590 12966  2244 11272 18556  7526\n",
      " 15476  8285 14481 18558 17803  6158  8746  6581  2449 17405  9651  3044\n",
      "  5124 13905 17836 15817  3835  1152  4835 10214  5074 17054 13324  6885\n",
      "  4623 12527  3431  9683 17278  8318 10436 11621 17157 12059 16857 19486\n",
      "  8130 17075  8355 15158]\n",
      "Selected symbolic variables (by index): (7,)\n",
      "Zeroing out columns [122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137] (corresponding to variable 7)\n",
      "\n",
      "Selected rows: [ 7270 10448  6531 12966 19791 10988  5223  3835 13933 18174  3426 12429\n",
      "  2112  3683 17910 13634  3593 10898 12542 15185    85  3962 11996 16803\n",
      "  2206 11458 15905 16799 18167  9649 14129  1639 14411  6503  3776 12889\n",
      " 14520 15884 11513 13631  7422  5764  1148  9630 11915 15522  1538  6118\n",
      "  6487  7072  1117 11832  1295 17894 15275 13315  4372  2249 18043 17143\n",
      " 13591 18637 12770   634  3416  4237 11148  4003 16425  4635  1097  9324\n",
      "  4507 18629  3113  5353  6406  8093 13608  6135 15605 16616 16022  6986\n",
      " 17497  7794   591  8250 12285 16607  6075  2422 13818    28 13230  6606\n",
      "  3909  6695  8901   763]\n",
      "Selected symbolic variables (by index): (8,)\n",
      "Zeroing out columns [138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153] (corresponding to variable 8)\n",
      "\n",
      "Selected rows: [ 3034  7247 11820  1748 16858 11471 17271  9433  9509  3319 16706  4408\n",
      "  4502  4611  5158  3538 19702 18121 11901  9485 15878  6110  4086 15276\n",
      " 14415 17698  5771 13809 12229  2092  5228  6353  9070 19571 16333 13630\n",
      "  8208 19580 15676 19487 17257  4328  5100 11355 12415   983 18655 15242\n",
      " 10190  7926 16323 18310 13785  5007 16659  1177 17942 10576  5166 19349\n",
      "  1425 16758 19162 10323  8647  7163 11191 18702 19234 10090  4252 13439\n",
      "  2807  4337 11265 10579  1052  1316   253 14312 19216 18406  8453  3202\n",
      "  9849  6068  8476 16800 13334  3672 11692 14810 15891 14683  4265  2764\n",
      " 19814  6331 11009 17524]\n",
      "Selected symbolic variables (by index): (9,)\n",
      "Zeroing out columns [154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169] (corresponding to variable 9)\n",
      "\n",
      "Selected rows: [ 6750 10699 16270  3287  9739 17243 11361  3567 19993 16600 12414 18774\n",
      " 12965 12469  7128  5817 15019  8642 12697 17191 14790 13039 19916 19050\n",
      " 19563  8066 18718 13792  1129  4644 11044  6735  6423 19143 18910 15806\n",
      "  7708 10945  9614    80  6412  7692 16261 18160 13106 11708 13217 18125\n",
      " 10143 19586  8993  2884  3043  4806 16499  2172  6504  4998  3648 11585\n",
      " 14562  4846  6086  7514  9599   385  1554  2353  6651   936 10295 12626\n",
      " 14740 17823 11269  5205 19196  3752 14931 12810 11683 14624   567 16939\n",
      "  5449  4392 18995 17557 15198 17993 19531  5164 13398 11600 18711   727\n",
      " 19673 19388 13923 17762]\n",
      "Selected symbolic variables (by index): (10,)\n",
      "Zeroing out columns [170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185] (corresponding to variable 10)\n",
      "\n",
      "Selected rows: [ 6170  1425 13482 16633 14112 19486 12579  2867  1520 16755 15777  3328\n",
      "   373 11701 14363  8273 15530  3488 15353 18547  7909 15829 14029  4552\n",
      "  3539 18097 14895  3448  9403  2149 11514 19876  2322  1148  5868 12375\n",
      " 16901  1898 15197  3185 11508  5109 11884 11147  6641  3793 15409 16311\n",
      "  4306 15547 11081 17087  1185  6381  6997 19283   278 15827 12117  5600\n",
      "  7063 15869 11291 11364  2528 16170 15030 12508 13507  9812  8707  9836\n",
      " 16895 16063  6235  8208 12147  2258 10992  1749  5334  3361 14478  3342\n",
      "  7999  8532  6768 14326  2637  3353 10690  4959 14115 17757 10135   296\n",
      "   876 14371 18474  6499]\n",
      "Selected symbolic variables (by index): (11,)\n",
      "Zeroing out columns [186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201] (corresponding to variable 11)\n",
      "\n",
      "Selected rows: [ 1074  1647  6586  7427 18814  9319 16766  2914   868  8631 18321 17534\n",
      "  7921   254  5598  3446 14819  8965 19207 12204 15089 19999  7654  6349\n",
      "  3821  9967 17547 12412  8694  4952  6725  2642 12764  4041 14100  7133\n",
      "  2845  5645 12622  8480   258 16850  5191  9650  9785  4306  3392 11052\n",
      "  9060 18569 10988 17450   165 17208 14467 15618  1991 13041  9498  4280\n",
      "  6093 15101  6192  7377 18759  5510  9079 13444    36 10331 12982 10437\n",
      " 13610  9415  3431 10892  2859 19027 12869 18740 15415  8896 11947 10666\n",
      "  4279  1505  7224  2963 16027 14572  9068 19264  9768 13910  5470   127\n",
      " 14712  9056 11116 12865]\n",
      "Selected symbolic variables (by index): (12,)\n",
      "Zeroing out columns [202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217] (corresponding to variable 12)\n",
      "\n",
      "Selected rows: [13477  4048 15905 15153   310 10962  8975  4390 10186 10776  9786 19031\n",
      "  8153 10363 10036 16596 15846  3539 11534  9193  9242 10839 11337  2424\n",
      "  6340 15177 18144 13599  5204  7140  6050  4319 10818  8739  2589 17466\n",
      "  2890 13612 13095 13606  3287 10236 16445   649 11303  5808 10075   776\n",
      " 19758 13679  7420 15698 17727 19450  2232   996  9325  8707  2803  4968\n",
      "  8659 19089  7779  9322   777  6070  1492 11024 10619 16546 13624 17043\n",
      " 17704 18250 14004 15215  4715 10905    65 12257  1761  3816 11165 16743\n",
      " 14195 16767 11667 12651  4145 14726 13546    20  6837 11791  4826  5319\n",
      "  2457 17862 14117 10450]\n",
      "Selected symbolic variables (by index): (13,)\n",
      "Zeroing out columns [218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233] (corresponding to variable 13)\n",
      "\n",
      "Selected rows: [11854  6658  3206 12749    97 17654  5785 10567 14680 16255  1491 11432\n",
      "   321  5365 11318   815   945 10947 13876 14647  9559  6600 14373  3537\n",
      " 12209  5843  5048 16028  2289   431 16093   700  6088  2548 11169 15641\n",
      " 10246 16042  5837 17924 19339  7587   866 10691  1091   456 12971  8981\n",
      "  3578 15789   854 17213   927  6354  6128  9597   861 18009  9437  8689\n",
      " 16841 19306  6263  2976  8831 12572  7306 16329   984  2584 14519  3607\n",
      " 18667  3212   582  9045 11831  1391 12058  9862 11529  6678 14576  2158\n",
      "  3791  1930  7901 18092 11226  8656 12542 12179  3603    83 10226  4164\n",
      "  3963 17448 16480 10092]\n",
      "Selected symbolic variables (by index): (14,)\n",
      "Zeroing out columns [234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249] (corresponding to variable 14)\n",
      "\n",
      "Selected rows: [16999  2740  3057  6918   911  4517  5700  3021 18561 11573  9747  2933\n",
      " 12859  5522 19069   413  3111  1986  9902 15536   270  5790 13247  8910\n",
      " 10091  8068  3128  8438 17381 19281 14521 11729 14908  1847  7609 10475\n",
      "  6409  7628  5087  3545 13899   961 15204 15629  5751 15776 18562   448\n",
      "  9682 16683 12603  9042 13733  5836 14184 17956 18833 15216  6977  7359\n",
      "  5689  8388  8255 16362 18898 10886 12015 14815  6856 17898  4807  6816\n",
      " 16660 14601  2473  3768  3952  2858  7415  1060 11985 11927 16520   296\n",
      " 17323  6908 17468 16012 13250  3413   421 12392 19022  5498  4221  8296\n",
      "  8310 12190 17321  8537]\n",
      "Selected symbolic variables (by index): (15,)\n",
      "Zeroing out columns [250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265] (corresponding to variable 15)\n",
      "\n",
      "Selected rows: [17559 19470  3683  8296 12744  5911  4457 14589  4796  9812 12869  1932\n",
      " 10572 13113  7318 13455  5114   399 15987  6291 11321  4543 10131 13191\n",
      " 13388 18752 10993  6439  6663 17254 19375 10223  4683 12611 15649   768\n",
      " 11630 18617 10813 13301 14885 15513  5787  5728  1020 12445  1332  9410\n",
      " 18574  7487  4434  2874   404  2956   569 12185 10321 10313 14157 17105\n",
      " 17060 15132 11423 13997  2273 13126  5716 19305   192   971  3482  6006\n",
      " 10611  4424 16338 15664 14850   212 13059  2754 17210 19545 10629   231\n",
      " 19921  1225 14523  4528 17063   958 18535 14517 11828 18588 11434 15780\n",
      "  4058  9250  2618  3002]\n",
      "Selected symbolic variables (by index): (16,)\n",
      "Zeroing out columns [266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281] (corresponding to variable 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded_copy = df_encoded.copy()\n",
    "X_missing_values = adding_missing_values(df_encoded_copy, indices, 1, 100)\n",
    "\n",
    "X_missing_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T15:19:29.331823Z",
     "start_time": "2025-08-06T15:19:29.301085Z"
    }
   },
   "id": "f16e1c065fedc0",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare Data for training and testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0c4be78c1aceb77"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_missing_values, df_encoded_copy, test_size=0.2, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T15:28:26.754546Z",
     "start_time": "2025-08-06T15:28:26.724743Z"
    }
   },
   "id": "3d826a54d472d688",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Constructing MLP using Keras"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce5acc76d58fc6eb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(input_dim, activation='sigmoid')  # output binario\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T15:28:33.840274Z",
     "start_time": "2025-08-06T15:28:33.759025Z"
    }
   },
   "id": "21d4d17169b62e24",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[BinaryAccuracy(name=\"bit_accuracy\")])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T15:28:34.805599Z",
     "start_time": "2025-08-06T15:28:34.797462Z"
    }
   },
   "id": "c0647bfada64b43c",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b87a806b1fabe16"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - bit_accuracy: 0.9431 - loss: 0.1671 - val_bit_accuracy: 0.9700 - val_loss: 0.0865\n",
      "Epoch 2/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9814 - loss: 0.0569 - val_bit_accuracy: 0.9886 - val_loss: 0.0375\n",
      "Epoch 3/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9921 - loss: 0.0274 - val_bit_accuracy: 0.9940 - val_loss: 0.0215\n",
      "Epoch 4/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9956 - loss: 0.0162 - val_bit_accuracy: 0.9960 - val_loss: 0.0145\n",
      "Epoch 5/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9972 - loss: 0.0107 - val_bit_accuracy: 0.9971 - val_loss: 0.0106\n",
      "Epoch 6/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9981 - loss: 0.0077 - val_bit_accuracy: 0.9977 - val_loss: 0.0086\n",
      "Epoch 7/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9987 - loss: 0.0057 - val_bit_accuracy: 0.9981 - val_loss: 0.0070\n",
      "Epoch 8/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9990 - loss: 0.0044 - val_bit_accuracy: 0.9985 - val_loss: 0.0059\n",
      "Epoch 9/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9992 - loss: 0.0035 - val_bit_accuracy: 0.9986 - val_loss: 0.0054\n",
      "Epoch 10/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9994 - loss: 0.0029 - val_bit_accuracy: 0.9987 - val_loss: 0.0049\n",
      "Epoch 11/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9995 - loss: 0.0023 - val_bit_accuracy: 0.9988 - val_loss: 0.0047\n",
      "Epoch 12/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9996 - loss: 0.0020 - val_bit_accuracy: 0.9989 - val_loss: 0.0044\n",
      "Epoch 13/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9997 - loss: 0.0016 - val_bit_accuracy: 0.9990 - val_loss: 0.0041\n",
      "Epoch 14/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9997 - loss: 0.0014 - val_bit_accuracy: 0.9990 - val_loss: 0.0041\n",
      "Epoch 15/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9998 - loss: 0.0012 - val_bit_accuracy: 0.9990 - val_loss: 0.0041\n",
      "Epoch 16/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9998 - loss: 0.0011 - val_bit_accuracy: 0.9990 - val_loss: 0.0041\n",
      "Epoch 17/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9998 - loss: 9.8183e-04 - val_bit_accuracy: 0.9990 - val_loss: 0.0039\n",
      "Epoch 18/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - bit_accuracy: 0.9998 - loss: 8.3734e-04 - val_bit_accuracy: 0.9990 - val_loss: 0.0040\n",
      "Epoch 19/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - bit_accuracy: 0.9998 - loss: 7.6280e-04 - val_bit_accuracy: 0.9990 - val_loss: 0.0039\n",
      "Epoch 20/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 6.9188e-04 - val_bit_accuracy: 0.9991 - val_loss: 0.0037\n",
      "Epoch 21/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 5.9041e-04 - val_bit_accuracy: 0.9991 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - bit_accuracy: 0.9999 - loss: 5.6263e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0039\n",
      "Epoch 23/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 5.2755e-04 - val_bit_accuracy: 0.9991 - val_loss: 0.0038\n",
      "Epoch 24/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 4.8077e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0039\n",
      "Epoch 25/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - bit_accuracy: 0.9999 - loss: 4.7097e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0037\n",
      "Epoch 26/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 4.0561e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0038\n",
      "Epoch 27/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 3.7400e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0037\n",
      "Epoch 28/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - bit_accuracy: 0.9999 - loss: 3.6807e-04 - val_bit_accuracy: 0.9991 - val_loss: 0.0040\n",
      "Epoch 29/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - bit_accuracy: 0.9999 - loss: 3.3813e-04 - val_bit_accuracy: 0.9991 - val_loss: 0.0040\n",
      "Epoch 30/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 2.9425e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0040\n",
      "Epoch 31/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - bit_accuracy: 0.9999 - loss: 3.1784e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0039\n",
      "Epoch 32/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 3.4256e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0041\n",
      "Epoch 33/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - bit_accuracy: 0.9999 - loss: 3.5216e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0040\n",
      "Epoch 34/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - bit_accuracy: 0.9999 - loss: 2.5625e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0038\n",
      "Epoch 35/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 2.8104e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0039\n",
      "Epoch 36/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 1.0000 - loss: 1.9239e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0039\n",
      "Epoch 37/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 1.0000 - loss: 1.9356e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0040\n",
      "Epoch 38/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 1.0000 - loss: 1.7302e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0041\n",
      "Epoch 39/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 2.8429e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0043\n",
      "Epoch 40/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 3.1130e-04 - val_bit_accuracy: 0.9991 - val_loss: 0.0046\n",
      "Epoch 41/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 3.3843e-04 - val_bit_accuracy: 0.9991 - val_loss: 0.0042\n",
      "Epoch 42/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 3.1401e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0041\n",
      "Epoch 43/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 1.0000 - loss: 1.7051e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0039\n",
      "Epoch 44/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - bit_accuracy: 1.0000 - loss: 1.3264e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0042\n",
      "Epoch 45/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 1.0000 - loss: 1.2973e-04 - val_bit_accuracy: 0.9993 - val_loss: 0.0040\n",
      "Epoch 46/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - bit_accuracy: 1.0000 - loss: 1.7227e-04 - val_bit_accuracy: 0.9993 - val_loss: 0.0038\n",
      "Epoch 47/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 2.5208e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0042\n",
      "Epoch 48/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 2.9258e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0043\n",
      "Epoch 49/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - bit_accuracy: 0.9999 - loss: 2.6143e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0043\n",
      "Epoch 50/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9999 - loss: 2.0413e-04 - val_bit_accuracy: 0.9992 - val_loss: 0.0041\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-03T12:16:55.819743Z",
     "start_time": "2025-08-03T12:16:26.678511Z"
    }
   },
   "id": "db474d9bd4a6742d",
   "execution_count": 314
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-03T12:16:55.823212Z",
     "start_time": "2025-08-03T12:16:55.821342Z"
    }
   },
   "id": "9e28bc7c88fa1424",
   "execution_count": 314
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36075f8cd604f01"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 535us/step\n",
      "0.9996708630837583\n"
     ]
    }
   ],
   "source": [
    "# Predizione\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Binarizzazione con soglia 0.8\n",
    "y_pred_binary = (y_pred > 0.8).astype(int)\n",
    "\n",
    "# Accuracy su tutti i bit\n",
    "accuracy_letter1 = (y_pred_binary == y_test).mean()\n",
    "\n",
    "# Accuracy solo sui bit mancanti\n",
    "test_mask = (X_test != 0).astype(int)\n",
    "missing_mask = (test_mask == 0)\n",
    "correct_missing = (y_pred_binary == y_test) & missing_mask\n",
    "accuracy_missing = correct_missing.sum() / missing_mask.sum()\n",
    "\n",
    "print(accuracy_missing)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T15:34:46.480660Z",
     "start_time": "2025-08-06T15:34:46.338055Z"
    }
   },
   "id": "bf9c381ce163cb03",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now i'm gonna test if the model can predict missing values using a different value of K"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b4aab7548b92a33"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d98b320a19931f6d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 590\n",
      "Epoch 1/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.3137 - val_bit_accuracy: 0.9397 - val_loss: 0.1889\n",
      "Epoch 2/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1892 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 3/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1891 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 4/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1891 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 5/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1890 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 6/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1890 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 7/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1890 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 8/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1890 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 9/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1890 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 10/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1890 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 11/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1890 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 12/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1890 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 13/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1890 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 14/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1889 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 15/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1889 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 16/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1889 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 17/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1889 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 18/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1889 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 19/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1889 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 20/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1888 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 21/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1888 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 22/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1888 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 23/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9397 - loss: 0.1888 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 24/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1888 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 25/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1888 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 26/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1888 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 27/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1888 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 28/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1887 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 29/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1887 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 30/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1887 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 31/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1887 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 32/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1887 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 33/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1887 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 34/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1887 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 35/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1887 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 36/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1887 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 37/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1887 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 38/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1887 - val_bit_accuracy: 0.9397 - val_loss: 0.1886\n",
      "Epoch 39/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1886 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 40/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1886 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 41/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1886 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 42/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1886 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 43/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1886 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 44/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1886 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 45/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1886 - val_bit_accuracy: 0.9397 - val_loss: 0.1887\n",
      "Epoch 46/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9398 - loss: 0.1886 - val_bit_accuracy: 0.9397 - val_loss: 0.1888\n",
      "Epoch 47/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9399 - loss: 0.1886 - val_bit_accuracy: 0.9396 - val_loss: 0.1888\n",
      "Epoch 48/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9399 - loss: 0.1886 - val_bit_accuracy: 0.9397 - val_loss: 0.1888\n",
      "Epoch 49/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - bit_accuracy: 0.9399 - loss: 0.1886 - val_bit_accuracy: 0.9396 - val_loss: 0.1888\n",
      "Epoch 50/50\n",
      "\u001B[1m400/400\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - bit_accuracy: 0.9399 - loss: 0.1886 - val_bit_accuracy: 0.9396 - val_loss: 0.1887\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 465us/step\n",
      "0.939723702979373\n"
     ]
    }
   ],
   "source": [
    "df_encoded_copy2 = df_encoded.copy()\n",
    "X_missing_values2 = adding_missing_values(df_encoded_copy2, indices, 4, 300)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_missing_values2, df_encoded_copy2, test_size=0.2, random_state=42)\n",
    "\n",
    "input_dim = X_train2.shape[1]\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(input_dim, activation='sigmoid')  # output binario\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[BinaryAccuracy(name=\"bit_accuracy\")])\n",
    "\n",
    "history2 = model.fit(\n",
    "    X_train2, y_train2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred2 = model.predict(X_test2)\n",
    "y_pred_binary2 = (y_pred2 > 0.8).astype(int)\n",
    "accuracy_letter2 = (y_pred_binary2 == y_test2).mean()\n",
    "\n",
    "test_mask2 = (X_test2 != 0).astype(int)  # 1 = osservato, 0 = mancato\n",
    "missing_mask2 = (test_mask2 == 0)\n",
    "\n",
    "# Calcola solo dove i bit erano mancanti\n",
    "correct_missing2 = (y_pred_binary2 == y_test2) & missing_mask2\n",
    "accuracy_missing2 = correct_missing2.sum() / missing_mask2.sum()\n",
    "print(accuracy_missing2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:19:07.129155Z",
     "start_time": "2025-08-06T16:18:40.252472Z"
    }
   },
   "id": "2787a91f2b2870b",
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LETS CONSIDER NOW THE SECOND DATASET"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba100924087b027a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     buying  maint  doors persons lug_boot safety  class\n0     vhigh  vhigh      2       2    small    low  unacc\n1     vhigh  vhigh      2       2    small    med  unacc\n2     vhigh  vhigh      2       2    small   high  unacc\n3     vhigh  vhigh      2       2      med    low  unacc\n4     vhigh  vhigh      2       2      med    med  unacc\n...     ...    ...    ...     ...      ...    ...    ...\n1723    low    low  5more    more      med    med   good\n1724    low    low  5more    more      med   high  vgood\n1725    low    low  5more    more      big    low  unacc\n1726    low    low  5more    more      big    med   good\n1727    low    low  5more    more      big   high  vgood\n\n[1728 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>buying</th>\n      <th>maint</th>\n      <th>doors</th>\n      <th>persons</th>\n      <th>lug_boot</th>\n      <th>safety</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>small</td>\n      <td>low</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>small</td>\n      <td>med</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>small</td>\n      <td>high</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>med</td>\n      <td>low</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>med</td>\n      <td>med</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1723</th>\n      <td>low</td>\n      <td>low</td>\n      <td>5more</td>\n      <td>more</td>\n      <td>med</td>\n      <td>med</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>1724</th>\n      <td>low</td>\n      <td>low</td>\n      <td>5more</td>\n      <td>more</td>\n      <td>med</td>\n      <td>high</td>\n      <td>vgood</td>\n    </tr>\n    <tr>\n      <th>1725</th>\n      <td>low</td>\n      <td>low</td>\n      <td>5more</td>\n      <td>more</td>\n      <td>big</td>\n      <td>low</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>1726</th>\n      <td>low</td>\n      <td>low</td>\n      <td>5more</td>\n      <td>more</td>\n      <td>big</td>\n      <td>med</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>1727</th>\n      <td>low</td>\n      <td>low</td>\n      <td>5more</td>\n      <td>more</td>\n      <td>big</td>\n      <td>high</td>\n      <td>vgood</td>\n    </tr>\n  </tbody>\n</table>\n<p>1728 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "columns2 = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\",\n",
    "            \"safety\", \"class\"]\n",
    "df2 = pd.read_csv(\"car.data\", delimiter=\",\", header=None, names=columns2)\n",
    "df2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:10:45.471480Z",
     "start_time": "2025-08-06T16:10:45.459290Z"
    }
   },
   "id": "e669b200f8489b15",
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One-Hot Encoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5083e1c64c04a019"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       ...,\n       [0., 1., 0., ..., 0., 1., 0.],\n       [0., 1., 0., ..., 1., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 1.]])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_encoded = encoder.fit_transform(df2).toarray()\n",
    "df2_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:10:47.030848Z",
     "start_time": "2025-08-06T16:10:47.018392Z"
    }
   },
   "id": "d5b009e0ead064c4",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:10:47.865779Z",
     "start_time": "2025-08-06T16:10:47.862457Z"
    }
   },
   "id": "b01d72b1e46904d5",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{0: range(0, 4),\n 1: range(4, 8),\n 2: range(8, 12),\n 3: range(12, 15),\n 4: range(15, 18),\n 5: range(18, 21),\n 6: range(21, 25)}"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "indices2 = {\n",
    "    0: range(0, 4), # buying\n",
    "    1: range(4, 8), # maint\n",
    "    2: range(8, 12), # doors\n",
    "    3: range(12, 15), # persons\n",
    "    4: range(15, 18), # lug_boot\n",
    "    5: range(18, 21), # safety\n",
    "    6: range(21, 25) #class\n",
    "}\n",
    "\"\"\"\n",
    "indices2 = build_indices(df2, columns2)\n",
    "indices2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:10:48.528765Z",
     "start_time": "2025-08-06T16:10:48.522268Z"
    }
   },
   "id": "23d4b075779c0351",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_df2 = adding_missing_values(df2_encoded, indices2, 1, 100)\n",
    "y2 = df2_encoded.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:10:50.603118Z",
     "start_time": "2025-08-06T16:10:50.597956Z"
    }
   },
   "id": "a91dd83243122f7d",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:10:51.377984Z",
     "start_time": "2025-08-06T16:10:51.375646Z"
    }
   },
   "id": "f8ccc1230df487a7",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X_df2, y2, test_size=0.2, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:08:16.675804Z",
     "start_time": "2025-08-06T16:08:16.671477Z"
    }
   },
   "id": "d4bc39735bc54845",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_dim_car = X3_train.shape[1]\n",
    "\n",
    "model_car = keras.Sequential([\n",
    "    layers.Input(shape=(input_dim_car,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(input_dim_car, activation='sigmoid')\n",
    "])\n",
    "model_car.compile(optimizer='adam', loss='binary_crossentropy', metrics=[BinaryAccuracy(name=\"bit_accuracy\")])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:08:19.250612Z",
     "start_time": "2025-08-06T16:08:19.231818Z"
    }
   },
   "id": "248bf914a156a351",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - bit_accuracy: 0.7293 - loss: 0.6653 - val_bit_accuracy: 0.7320 - val_loss: 0.6147\n",
      "Epoch 2/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7376 - loss: 0.5748 - val_bit_accuracy: 0.7320 - val_loss: 0.5668\n",
      "Epoch 3/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7376 - loss: 0.5562 - val_bit_accuracy: 0.7320 - val_loss: 0.5640\n",
      "Epoch 4/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - bit_accuracy: 0.7376 - loss: 0.5537 - val_bit_accuracy: 0.7320 - val_loss: 0.5642\n",
      "Epoch 5/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - bit_accuracy: 0.7378 - loss: 0.5523 - val_bit_accuracy: 0.7321 - val_loss: 0.5642\n",
      "Epoch 6/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7387 - loss: 0.5508 - val_bit_accuracy: 0.7324 - val_loss: 0.5644\n",
      "Epoch 7/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7405 - loss: 0.5490 - val_bit_accuracy: 0.7339 - val_loss: 0.5639\n",
      "Epoch 8/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7417 - loss: 0.5476 - val_bit_accuracy: 0.7346 - val_loss: 0.5627\n",
      "Epoch 9/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7431 - loss: 0.5458 - val_bit_accuracy: 0.7346 - val_loss: 0.5644\n",
      "Epoch 10/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7437 - loss: 0.5446 - val_bit_accuracy: 0.7344 - val_loss: 0.5629\n",
      "Epoch 11/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7445 - loss: 0.5438 - val_bit_accuracy: 0.7347 - val_loss: 0.5636\n",
      "Epoch 12/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7448 - loss: 0.5425 - val_bit_accuracy: 0.7342 - val_loss: 0.5633\n",
      "Epoch 13/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7455 - loss: 0.5413 - val_bit_accuracy: 0.7337 - val_loss: 0.5650\n",
      "Epoch 14/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7454 - loss: 0.5407 - val_bit_accuracy: 0.7330 - val_loss: 0.5640\n",
      "Epoch 15/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7455 - loss: 0.5404 - val_bit_accuracy: 0.7334 - val_loss: 0.5683\n",
      "Epoch 16/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7459 - loss: 0.5395 - val_bit_accuracy: 0.7327 - val_loss: 0.5649\n",
      "Epoch 17/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7460 - loss: 0.5389 - val_bit_accuracy: 0.7330 - val_loss: 0.5651\n",
      "Epoch 18/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - bit_accuracy: 0.7466 - loss: 0.5385 - val_bit_accuracy: 0.7326 - val_loss: 0.5649\n",
      "Epoch 19/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - bit_accuracy: 0.7465 - loss: 0.5380 - val_bit_accuracy: 0.7331 - val_loss: 0.5637\n",
      "Epoch 20/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7465 - loss: 0.5377 - val_bit_accuracy: 0.7330 - val_loss: 0.5647\n",
      "Epoch 21/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7468 - loss: 0.5374 - val_bit_accuracy: 0.7331 - val_loss: 0.5654\n",
      "Epoch 22/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - bit_accuracy: 0.7469 - loss: 0.5366 - val_bit_accuracy: 0.7321 - val_loss: 0.5659\n",
      "Epoch 23/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7471 - loss: 0.5365 - val_bit_accuracy: 0.7333 - val_loss: 0.5662\n",
      "Epoch 24/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7474 - loss: 0.5359 - val_bit_accuracy: 0.7323 - val_loss: 0.5658\n",
      "Epoch 25/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7475 - loss: 0.5357 - val_bit_accuracy: 0.7330 - val_loss: 0.5670\n",
      "Epoch 26/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7479 - loss: 0.5357 - val_bit_accuracy: 0.7318 - val_loss: 0.5658\n",
      "Epoch 27/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7475 - loss: 0.5352 - val_bit_accuracy: 0.7321 - val_loss: 0.5653\n",
      "Epoch 28/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7477 - loss: 0.5344 - val_bit_accuracy: 0.7327 - val_loss: 0.5662\n",
      "Epoch 29/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7477 - loss: 0.5345 - val_bit_accuracy: 0.7327 - val_loss: 0.5691\n",
      "Epoch 30/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7479 - loss: 0.5348 - val_bit_accuracy: 0.7330 - val_loss: 0.5700\n",
      "Epoch 31/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7482 - loss: 0.5337 - val_bit_accuracy: 0.7329 - val_loss: 0.5694\n",
      "Epoch 32/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7480 - loss: 0.5340 - val_bit_accuracy: 0.7326 - val_loss: 0.5710\n",
      "Epoch 33/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7484 - loss: 0.5333 - val_bit_accuracy: 0.7329 - val_loss: 0.5688\n",
      "Epoch 34/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7484 - loss: 0.5335 - val_bit_accuracy: 0.7330 - val_loss: 0.5718\n",
      "Epoch 35/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7483 - loss: 0.5333 - val_bit_accuracy: 0.7326 - val_loss: 0.5685\n",
      "Epoch 36/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7487 - loss: 0.5324 - val_bit_accuracy: 0.7323 - val_loss: 0.5697\n",
      "Epoch 37/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7481 - loss: 0.5323 - val_bit_accuracy: 0.7329 - val_loss: 0.5689\n",
      "Epoch 38/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7486 - loss: 0.5321 - val_bit_accuracy: 0.7326 - val_loss: 0.5707\n",
      "Epoch 39/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7485 - loss: 0.5320 - val_bit_accuracy: 0.7323 - val_loss: 0.5687\n",
      "Epoch 40/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7491 - loss: 0.5320 - val_bit_accuracy: 0.7321 - val_loss: 0.5708\n",
      "Epoch 41/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7491 - loss: 0.5317 - val_bit_accuracy: 0.7321 - val_loss: 0.5696\n",
      "Epoch 42/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7489 - loss: 0.5320 - val_bit_accuracy: 0.7317 - val_loss: 0.5698\n",
      "Epoch 43/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7494 - loss: 0.5315 - val_bit_accuracy: 0.7317 - val_loss: 0.5722\n",
      "Epoch 44/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7495 - loss: 0.5314 - val_bit_accuracy: 0.7321 - val_loss: 0.5709\n",
      "Epoch 45/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7492 - loss: 0.5310 - val_bit_accuracy: 0.7316 - val_loss: 0.5711\n",
      "Epoch 46/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7494 - loss: 0.5315 - val_bit_accuracy: 0.7326 - val_loss: 0.5738\n",
      "Epoch 47/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7498 - loss: 0.5307 - val_bit_accuracy: 0.7311 - val_loss: 0.5726\n",
      "Epoch 48/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7495 - loss: 0.5306 - val_bit_accuracy: 0.7317 - val_loss: 0.5727\n",
      "Epoch 49/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - bit_accuracy: 0.7499 - loss: 0.5304 - val_bit_accuracy: 0.7336 - val_loss: 0.5734\n",
      "Epoch 50/50\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - bit_accuracy: 0.7494 - loss: 0.5304 - val_bit_accuracy: 0.7316 - val_loss: 0.5730\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n",
      "Missing value reconstruction accuracy (k=4): 0.7231323341466248\n"
     ]
    }
   ],
   "source": [
    "X_df4 = adding_missing_values(df2_encoded, indices2, 4, 300)\n",
    "y4 = df2_encoded.copy()\n",
    "\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X_df4, y4, test_size=0.2, random_state=42)\n",
    "\n",
    "input_dim_car = X4_train.shape[1]\n",
    "\n",
    "model_car = keras.Sequential([\n",
    "    layers.Input(shape=(input_dim_car,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(input_dim_car, activation='sigmoid')\n",
    "])\n",
    "model_car.compile(optimizer='adam', loss='binary_crossentropy', metrics=[BinaryAccuracy(name=\"bit_accuracy\")])\n",
    "\n",
    "history4 = model_car.fit(\n",
    "    X4_train, y4_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_pred4 = model_car.predict(X4_test)\n",
    "\n",
    "# Binarize output\n",
    "y_pred_binary4 = (y_pred4 > 0.8).astype(int)\n",
    "\n",
    "# Global accuracy\n",
    "accuracy_car4 = (y_pred_binary4 == y4_test).mean()\n",
    "\n",
    "# Accuracy only on missing bits\n",
    "test_mask4 = (X4_test != 0).astype(int)\n",
    "missing_mask4 = (test_mask4 == 0)\n",
    "correct_missing4 = (y_pred_binary4 == y4_test) & missing_mask4\n",
    "accuracy_missing4 = correct_missing4.sum() / missing_mask4.sum()\n",
    "\n",
    "print(accuracy_missing4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:17:33.195215Z",
     "start_time": "2025-08-06T16:17:27.151166Z"
    }
   },
   "id": "ded357ce86e3322f",
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now i'm gonna test if the model can predict missing values using a different value of K\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8233b448e514ad2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 25 is out of bounds for axis 1 with size 25",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[55]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m df_encoded_copy4 = df2_encoded.copy()\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m X_missing_values4 = adding_missing_values(df_encoded_copy4, indices, \u001B[32m1\u001B[39m, \u001B[32m100\u001B[39m)\n\u001B[32m      4\u001B[39m X_train4, X_test4, y_train4, y_test4 = train_test_split(\n\u001B[32m      5\u001B[39m     X_missing_values4, y2, test_size=\u001B[32m0.2\u001B[39m, random_state=\u001B[32m42\u001B[39m\n\u001B[32m      6\u001B[39m )\n\u001B[32m      7\u001B[39m input_dim_car = X_train4.shape[\u001B[32m1\u001B[39m]\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 17\u001B[39m, in \u001B[36madding_missing_values\u001B[39m\u001B[34m(data, indices, k, m)\u001B[39m\n\u001B[32m     15\u001B[39m         column_indices = \u001B[38;5;28mlist\u001B[39m(indices[col])\n\u001B[32m     16\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m column_indices:\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m             X[rows, j] = \u001B[32m0.0\u001B[39m\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m X\n",
      "\u001B[31mIndexError\u001B[39m: index 25 is out of bounds for axis 1 with size 25"
     ]
    }
   ],
   "source": [
    "df_encoded_copy4 = df2_encoded.copy()\n",
    "\n",
    "X_missing_values4 = adding_missing_values(df_encoded_copy4, indices, 1, 100)\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(\n",
    "    X_missing_values4, y2, test_size=0.2, random_state=42\n",
    ")\n",
    "input_dim_car = X_train4.shape[1]\n",
    "\n",
    "model_car = keras.Sequential([\n",
    "    layers.Input(shape=(input_dim_car,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(input_dim_car, activation='sigmoid')\n",
    "])\n",
    "model_car.compile(optimizer='adam', loss='binary_crossentropy', metrics=[BinaryAccuracy(name=\"bit_accuracy\")])\n",
    "history4 = model_car.fit(\n",
    "    X_train4, y_train4,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred4 = model_car.predict(X_test4)\n",
    "y_pred_binary4 = (y_pred4 > 0.8).astype(int)\n",
    "\n",
    "accuracy_car4 = ((y_pred_binary4 == y_test4).values).mean()\n",
    "\n",
    "# Accuracy only on missing values\n",
    "test_mask4 = (X_test4 != 0).astype(int)\n",
    "missing_mask4 = (test_mask4 == 0)\n",
    "correct_missing4 = (y_pred_binary4 == y_test4) & missing_mask4\n",
    "accuracy_missing4 = correct_missing4.sum() / missing_mask4.sum()\n",
    "print(\"Accuracy on missing values:\", accuracy_missing4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:15:26.257437Z",
     "start_time": "2025-08-06T16:15:26.214538Z"
    }
   },
   "id": "1c36c078c4b61a85",
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9541ae354038b807"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Letters (1-miss)\": {\"bitwise\": accuracy_letter1, \"missing\": accuracy_missing},\n",
    "    \"Letters (4-miss)\": {\"bitwise\": accuracy_letter2, \"missing\": accuracy_missing2},\n",
    "    \"Cars (1-miss)\": {\"bitwise\": accuracy_car3, \"missing\": accuracy_missing3},\n",
    "    \"Cars (4-miss)\": {\"bitwise\": accuracy_car4, \"missing\": accuracy_missing4}\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:21:26.016103Z",
     "start_time": "2025-08-06T16:21:26.011751Z"
    }
   },
   "id": "85596e4aff05588f",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x600 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAi3xJREFUeJzs3XdcleX/x/H3AWUIAiqIYijulRMVR67CneZelYojK83Kvq4cOErT0jRnmit3mZqmaebIHLmxzL1NQSQHigoI9+8PH5yfR0DB4Mbxej4e51Fc57rP+dyHc99y3ue6rttiGIYhAAAAAAAAwER2GV0AAAAAAAAAnj+EUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAK4vFoqFDh5r+vHPmzJHFYtGZM2dMf248e86cOSOLxaI5c+ak+WNn1DEiSZ06dZKrq2uK+mZknUBa8PPzU6dOnTK6DABAOiOUAoBnWELYc/8tZ86cql27tn7++edHbr99+3YNHTpU165dS/9iM1Dfvn1lsVjUpk2bjC4F9xk6dKgsFovs7Ox0/vz5RPdHRkbK2dlZFotFPXv2zIAKnx7/5Vhu3bq1LBaL+vXrl/aFIV116tQp0b8BCTcnJ6eMLu+pd+jQIQ0dOpQvVADgP8iU0QUAANLf8OHDlT9/fhmGoUuXLmnOnDlq2LChVq1apVdffdXa7/bt28qU6f//adi+fbuGDRumTp06ycPDI93qe/PNN9W2bVs5Ojqm23MkxzAMLVq0SH5+flq1apVu3LihrFmzml4Hkufo6KhFixapb9++Nu3Lli1Lsn++fPl0+/ZtZc6cOc1refAYeVKl1bEcGRmpVatWyc/PT4sWLdJnn30mi8WSDhUjvTg6Ouqbb75J1G5vb58B1aTc0aNHZWf3ZH9/fujQIQ0bNky1atWSn59fRpcDAE+lJ/+vKgDAf9agQQNVqFDB+nOXLl3k7e2tRYsW2YRSGfXNub29fYZ9QNq8ebP++ecfbdy4UfXq1dOyZcvUsWPHDKnlUW7duqUsWbJkdBmma9iwYZKh1MKFC9WoUSP98MMPNu3pOQrkaRldklZ1/vDDD4qLi9OsWbP08ssva8uWLapZs2aaPHZaMgxDd+7ckbOzc0aXYqqU7HemTJn0xhtvmFjV47t/fzLiSwoAgPme7K8fAADpwsPDQ87OzolGfNy/Ds3QoUPVp08fSVL+/PmtUz4eNk2hfPnyat68uU1bqVKlZLFY9Oeff1rblixZIovFosOHD0tKek2pPXv2qF69evL09JSzs7Py58+vzp072zx2fHy8xo8fr5IlS8rJyUne3t7q3r27rl69muLXYsGCBSpRooRq166twMBALViwIMl+Fy5cUJcuXeTj4yNHR0flz59f77zzjmJiYqx9rl27pg8//FB+fn5ydHTUCy+8oA4dOigiIiLZ/ZTuBWMWi0WbN2+2ttWqVUsvvvii9u7dqxo1aihLliz6+OOPJUk//vijGjVqZK2lYMGCGjFihOLi4hLVvXPnTjVs2FDZsmWTi4uLSpcurQkTJkiSZs+eLYvFov379yfabuTIkbK3t9eFCxeSfD2WLl0qi8Wi3377LdF9X3/9tSwWiw4ePChJCgsLU1BQkF544QU5Ojoqd+7ceu2111I85aV9+/YKCQnRkSNHrG1hYWHauHGj2rdvn6h/UmtKpaSGlLznHlyrKWGK4YkTJ6yjkNzd3RUUFKRbt27ZbHv79m316tVLnp6eypo1q5o0aaILFy6kev2nU6dOqV69enJxcZGPj4+GDx8uwzCSrfNxjuUECxYsUJ06dVS7dm0VL1482ePjyJEjat26tby8vOTs7KyiRYtq4MCBNn0edQwlvJYPSuq48fPz06uvvqp169apQoUKcnZ21tdffy3p3vv65ZdfVs6cOeXo6KgSJUpo6tSpSdb9888/q2bNmsqaNavc3NxUsWJFLVy4UJIUHByszJkz6/Lly4m2e+utt+Th4aE7d+4k+9olrAGWkt9XSs9lD9vv/yI2NlbDhg1T4cKF5eTkpBw5cuill17S+vXrM2x/HlxTKuF9sHXrVvXq1UteXl7y8PBQ9+7dFRMTo2vXrqlDhw7Kli2bsmXLpr59+/7nurZu3apKlSrJyclJBQoU0LfffmtTT6tWrSRJtWvXth5X95/Hp0yZopIlS8rR0VE+Pj7q0aPHMz8dHgBSi5FSAPAcuH79uiIiImQYhsLDwzVx4kTdvHnzod+eN2/eXMeOHdOiRYv05ZdfytPTU5Lk5eWV7DbVq1fXokWLrD9fuXJFf//9t+zs7PT777+rdOnSkqTff/9dXl5eKl68eJKPEx4errp168rLy0v9+/eXh4eHzpw5k2i6Vvfu3TVnzhwFBQWpV69eOn36tCZNmqT9+/dr27Ztj5y+FR0drR9++EEfffSRJKldu3YKCgpSWFiYcuXKZe138eJFVapUSdeuXdNbb72lYsWK6cKFC1q6dKlu3bolBwcH3bx5U9WrV9fhw4fVuXNnlS9fXhEREVq5cqX++ecf6+uXGv/++68aNGigtm3b6o033pC3t7ekex+GXF1d1bt3b7m6umrjxo0aMmSIIiMj9fnnn1u3X79+vV599VXlzp1b77//vnLlyqXDhw/rp59+0vvvv6+WLVuqR48eWrBggcqVK2fz3AsWLFCtWrWUJ0+eJGtr1KiRXF1d9d133yUaObNkyRKVLFlSL774oiSpRYsW+vvvv/Xee+/Jz89P4eHhWr9+vc6dO5eiKS81atTQCy+8oIULF2r48OHW53B1dVWjRo1S9Fo+qoaUvueS07p1a+XPn1+jRo3Svn379M033yhnzpwaPXq0tU+nTp303Xff6c0331TlypX122+/pbj+BHFxcapfv74qV66sMWPGaO3atQoODtbdu3etr82DHudYlu697zdt2qS5c+dKund8fPnll5o0aZIcHBys/f78809Vr15dmTNn1ltvvSU/Pz+dPHlSq1at0qeffmp9rEcdQ6l19OhRtWvXTt27d1e3bt1UtGhRSdLUqVNVsmRJNWnSRJkyZdKqVav07rvvKj4+Xj169LBuP2fOHHXu3FklS5bUgAED5OHhof3792vt2rVq37693nzzTQ0fPlxLliyxWbMsJiZGS5cuVYsWLR45Ii2lv6/UnMuS2++HSQjG7+fg4CA3NzdJ9wLBUaNGqWvXrqpUqZIiIyO1Z88e7du3T3Xq1Hmi9ue9995Trly5NGzYMP3xxx+aPn26PDw8tH37duXNm1cjR47UmjVr9Pnnn+vFF19Uhw4dHquuEydOqGXLlurSpYs6duyoWbNmqVOnTvL391fJkiVVo0YN9erVS1999ZU+/vhj679nCf8dOnSohg0bpsDAQL3zzjs6evSopk6dqt27d6fo3ycAeG4YAIBn1uzZsw1JiW6Ojo7GnDlzEvWXZAQHB1t//vzzzw1JxunTp1P0fN9//70hyTh06JBhGIaxcuVKw9HR0WjSpInRpk0ba7/SpUsbzZo1S1RnwvMsX77ckGTs3r072ef6/fffDUnGggULbNrXrl2bZHtSli5dakgyjh8/bhiGYURGRhpOTk7Gl19+adOvQ4cOhp2dXZL1xMfHG4ZhGEOGDDEkGcuWLUu2z4P7mWDTpk2GJGPTpk3Wtpo1axqSjGnTpiV6vFu3biVq6969u5ElSxbjzp07hmEYxt27d438+fMb+fLlM65evZpkPYZhGO3atTN8fHyMuLg4a9u+ffsMScbs2bMTPc/92rVrZ+TMmdO4e/eutS00NNSws7Mzhg8fbhiGYVy9etWQZHz++ecPfaykBAcHG5KMy5cvG//73/+MQoUKWe+rWLGiERQUZBjGvfdtjx49rPedPn3apv6U1JCS91zCc91/jCTU2LlzZ5t+zZo1M3LkyGH9ee/evYYk44MPPrDp16lTp0SPmZyOHTsakoz33nvP2hYfH280atTIcHBwMC5fvpxsnak9lg3DML744gvD2dnZiIyMNAzDMI4dO2ZIMpYvX27Tr0aNGkbWrFmNs2fP2rTf/z5LyTGU8Fo+KKnjJl++fIYkY+3atYn6J3V81KtXzyhQoID152vXrhlZs2Y1AgICjNu3bydbd5UqVYyAgACb+5ctW5boeE1KSn9fqTmXPWy/H1ZDUrd69epZ+5UpU8Zo1KjRE7U/+fLlMzp27Gj9OeF9UK9evUS/I4vFYrz99tvWtrt37xovvPCCUbNmTWvb49S1ZcsWa1t4eLjh6OhofPTRR9a2hH/zHnwvhIeHGw4ODkbdunVtzq2TJk0yJBmzZs1KtL8A8Lxi+h4APAcmT56s9evXa/369Zo/f75q166trl27pngUSEpVr15dkrRlyxZJ90ZEVaxYUXXq1NHvv/8u6d4Ut4MHD1r7JiVhIeaffvpJsbGxSfb5/vvv5e7urjp16igiIsJ68/f3l6urqzZt2vTIehcsWKAKFSqoUKFCkqSsWbOqUaNGNlOU4uPjtWLFCjVu3NhmXa4ECdONfvjhB5UpU0bNmjVLtk9qOTo6KigoKFH7/evH3LhxQxEREapevbpu3bplneK2f/9+nT59Wh988EGiha3vr6dDhw7WETEJFixYIGdnZ7Vo0eKh9bVp00bh4eE201WWLl2q+Ph465UMnZ2d5eDgoM2bN6dqWuWD2rdvrxMnTmj37t3W/yY1dS8pKakhJe+5h3n77bdtfq5evbr+/fdfRUZGSpLWrl0rSXr33Xdt+r333nupfq77R+0kXHkwJiZGv/76a6of62EWLFigRo0aWRf+L1y4sPz9/W2Oj8uXL2vLli3q3Lmz8ubNa7N9wvsspcdQauXPn1/16tVL1H7/8ZEwSrRmzZo6deqUrl+/LuneKMIbN26of//+iUY7PXh87Ny5UydPnrS2LViwQL6+vileW+tRv6/UnsuS2+/kODk5Wc//998+++wzax8PDw/9/fffOn78+BO/P126dLH5HQUEBMgwDHXp0sXaZm9vrwoVKujUqVPWttTWVaJECZt/p7y8vFS0aFGbx0zOr7/+qpiYGH3wwQc2i7V369ZNbm5uWr16dYr3FwCedYRSAPAcqFSpkgIDAxUYGKjXX39dq1evVokSJawfJlLrypUrCgsLs94SPuh5e3urcOHC1gDq999/V/Xq1VWjRg1dvHhRp06d0rZt2xQfH//QUKpmzZpq0aKFhg0bJk9PT7322muaPXu2oqOjrX2OHz+u69evK2fOnPLy8rK53bx5U+Hh4Q/dh2vXrmnNmjWqWbOmTpw4Yb1Vq1ZNe/bs0bFjxyTd+9AdGRlpnYqWnJMnTz6yT2rlyZMnyWlNf//9t5o1ayZ3d3e5ubnJy8vLOhUz4XeR8CH6UTXVqVNHuXPntgYN8fHxWrRokV577bVHXoWwfv36cnd315IlS6xtS5YsUdmyZVWkSBFJ94K10aNH6+eff5a3t7dq1KihMWPGKCwsLIWvwj3lypVTsWLFtHDhQi1YsEC5cuXSyy+/nKJtU1JDSt5zD/NgIJMtWzZJsoZgZ8+elZ2dnfLnz2/TLyEQTRATE2NzbIWFhdmsFWZnZ6cCBQrYbJPwWqflZekPHz6s/fv3q1q1ajbHR61atfTTTz9Zw7aED+gPe5+l9BhKrQdfywTbtm1TYGCgXFxc5OHhIS8vL+t6bKk9Ptq0aSNHR0fr8XH9+nX99NNPev3111MUpqXk95Xac1ly+50ce3t76/n//lvZsmWtfYYPH65r166pSJEiKlWqlPr06WOzDuCTtD8PHmvu7u6SJF9f30Tt94fQqa3rweeR7h3XKQnXz549K0mJpiI6ODioQIEC1vsBAKwpBQDPJTs7O9WuXVsTJkzQ8ePHVbJkyVRt37x5c5sFrjt27GhdVPqll17Shg0bdPv2be3du1dDhgzRiy++KA8PD/3+++86fPiwXF1dE61hdD+LxaKlS5fqjz/+0KpVq7Ru3Tp17txZY8eO1R9//CFXV1fFx8crZ86cyS68/Kj1cr7//ntFR0dr7NixGjt2bKL7FyxYoGHDhqXg1Ui55D7EJrVAuaQkr6h17do11axZU25ubho+fLgKFiwoJycn7du3T/369VN8fHyqarK3t1f79u01Y8YMTZkyRdu2bdPFixdTdLUuR0dHNW3aVMuXL9eUKVN06dIlbdu2TSNHjrTp98EHH6hx48ZasWKF1q1bp8GDB2vUqFHauHHjQ98HD2rfvr2mTp2qrFmzqk2bNqm6XPyjakjJe+5hkrt6pPHAQsuPsn37dtWuXdum7fTp06Zfbn7+/PmSpA8//FAffvhhovt/+OGHJEfx/RdpcXycPHlSr7zyiooVK6Zx48bJ19dXDg4OWrNmjb788stUHx/ZsmXTq6++qgULFmjIkCFaunSpoqOj0/Rqdqk9l6XHFQZr1KihkydP6scff9Qvv/yib775Rl9++aWmTZumrl27puqx0nt/kjvWkmq///hLbV1pdUwDAB6OUAoAnlN3796VJN28eTPZPsl9SBw7dqzNt8U+Pj7W/69evbpmz56txYsXKy4uTlWrVpWdnZ1eeuklayhVtWrVZP/gv1/lypVVuXJlffrpp1q4cKFef/11LV68WF27dlXBggX166+/qlq1ao/1IW3BggV68cUXFRwcnOi+r7/+WgsXLtSwYcPk5eUlNzc365XkklOwYMFH9kkYPfPg1ZdS86355s2b9e+//2rZsmWqUaOGtf306dOJ6pGkgwcPKjAw8KGP2aFDB40dO1arVq3Szz//LC8vrxRPp2nTpo3mzp2rDRs26PDhwzIMwzp178F6PvroI3300Uc6fvy4ypYtq7Fjx1rDj5Ro3769hgwZotDQUM2bNy/F26Wmhoe95/6LfPnyKT4+XqdPn1bhwoWt7SdOnLDpV6ZMGZsrnkmyWXQ/Pj5ep06dso5OkWQd1few4Co1U+QMw9DChQtVu3btRNMNJWnEiBFasGCBgoKCrKNmHvbeT+kxdP/xcf+U09QcH6tWrVJ0dLRWrlxpM9LlwalZ9x8fD45We1CHDh302muvaffu3daLAqQ0yE/J7+u/nsvSSvbs2RUUFKSgoCDdvHlTNWrU0NChQ23e+0/T/jwoPepK7rjKly+fpHuLuN8/siwmJkanT59+5DkZAJ4nTN8DgOdQbGysfvnlFzk4OCR7BTxJcnFxkZQ4RPH397eZBlKiRAnrfQnT8kaPHq3SpUtbp1ZUr15dGzZs0J49ex46dU+6N+XpwW+jE6aaJEynat26teLi4jRixIhE29+9e/ehl90+f/68tmzZotatW6tly5aJbkFBQTpx4oR27twpOzs7NW3aVKtWrdKePXsSPVZCnS1atNCBAwe0fPnyZPskfBBOWHNLujcKZPr06Q95NWwlhHn3vz4xMTGaMmWKTb/y5csrf/78Gj9+fKLX4sHXtnTp0ipdurS++eYb/fDDD2rbtq0yZUrZ91aBgYHKnj27lixZoiVLlqhSpUo203Fu3bqlO3fu2GxTsGBBZc2aNcVT4+7fbvz48Ro1apQqVaqU4u1SUkNK3nP/RULI9+DvaeLEiTY/Z8uWLdE0qwfXPJo0aZL1/w3D0KRJk5Q5c2a98soryT5/csdyUrZt26YzZ84oKCgoyeOjTZs22rRpky5evCgvLy/VqFFDs2bN0rlz52weJ+H1TOkxlNTxERUVZb36X0okdXxcv35ds2fPtulXt25dZc2aVaNGjUr03njwfdCgQQN5enpq9OjR+u2331I9SupRv6//ci5LK//++6/Nz66uripUqFCS7/2nYX+Skh51JXdcBQYGysHBQV999ZXN+2nmzJm6fv16qq+6CQDPMkZKAcBz4Oeff7YugB0eHq6FCxfq+PHj6t+/v/WS4Enx9/eXJA0cOFBt27ZV5syZ1bhxY+sf4kkpVKiQcuXKpaNHj9os4lyjRg3169dPkh4ZSs2dO1dTpkxRs2bNVLBgQd24cUMzZsyQm5ubGjZsKOneGkDdu3fXqFGjFBISorp16ypz5sw6fvy4vv/+e02YMEEtW7ZM8vEXLlwowzDUpEmTJO9v2LChMmXKpAULFiggIEAjR47UL7/8opo1a+qtt95S8eLFFRoaqu+//15bt26Vh4eH+vTpo6VLl6pVq1bq3Lmz/P39deXKFa1cuVLTpk1TmTJlVLJkSVWuXFkDBgzQlStXlD17di1evNg6ai0lqlatqmzZsqljx47q1auXLBaL5s2bl+iDtJ2dnaZOnarGjRurbNmyCgoKUu7cuXXkyBH9/fffWrdunU3/Dh066H//+58kpepDd+bMmdW8eXMtXrxYUVFR+uKLL2zuP3bsmF555RW1bt1aJUqUUKZMmbR8+XJdunRJbdu2TfHzJHj//fdTvU1KakjJe+6/8Pf3V4sWLTR+/Hj9+++/qly5sn777TfrKJOUjmRycnLS2rVr1bFjRwUEBOjnn3/W6tWr9fHHHz90ympqjuUFCxbI3t4+2Q/OTZo00cCBA7V48WL17t1bX331lV566SWVL19eb731lvLnz68zZ85o9erVCgkJkaQUHUN169ZV3rx51aVLF/Xp00f29vaaNWuWvLy8EgVeyalbt64cHBzUuHFjde/eXTdv3tSMGTOUM2dOhYaGWvu5ubnpyy+/VNeuXVWxYkW1b99e2bJl04EDB3Tr1i2bICxz5sxq27atJk2aJHt7e7Vr1y5FtUgp+339l3NZSty9ezfZEYnNmjWTi4uLSpQooVq1asnf31/Zs2fXnj17tHTpUptFzZ+U/Xlc6VFX2bJlZW9vr9GjR+v69etydHTUyy+/rJw5c2rAgAEaNmyY6tevryZNmujo0aOaMmWKKlasmKbTPwHgqWfmpf4AAOZKuIT2/TcnJyejbNmyxtSpU20uq20YiS8jbxiGMWLECCNPnjyGnZ1dii8p36pVK0OSsWTJEmtbTEyMkSVLFsPBwSHRJdgfvOT7vn37jHbt2hl58+Y1HB0djZw5cxqvvvqqsWfPnkTPNX36dMPf399wdnY2smbNapQqVcro27evcfHixWTrK1WqlJE3b96H7kOtWrWMnDlzGrGxsYZhGMbZs2eNDh06GF5eXoajo6NRoEABo0ePHkZ0dLR1m3///dfo2bOnkSdPHsPBwcF44YUXjI4dOxoRERHWPidPnjQCAwMNR0dHw9vb2/j444+N9evXJ7qseM2aNY2SJUsmWdu2bduMypUrG87OzoaPj4/Rt29fY926dUlemnzr1q1GnTp1jKxZsxouLi5G6dKljYkTJyZ6zNDQUMPe3t4oUqTIQ1+XpCTUb7FYjPPnz9vcFxERYfTo0cMoVqyY4eLiYri7uxsBAQHGd99998jHDQ4ONiRZLzWfHElGjx49rD+fPn3akGTMnj07xTWk9D334DGSXI0PvqcNwzCioqKMHj16GNmzZzdcXV2Npk2bGkePHjUkGZ999tkjX4+OHTsaLi4uxsmTJ426desaWbJkMby9vY3g4GCby84nVadhpOxYjomJMXLkyGFUr179obXkz5/fKFeunPXngwcPGs2aNTM8PDwMJycno2jRosbgwYNttknJMbR3714jICDAcHBwMPLmzWuMGzcuydcyX758RqNGjZKsbeXKlUbp0qUNJycnw8/Pzxg9erQxa9asJPd55cqVRtWqVQ1nZ2fDzc3NqFSpkrFo0aJEj7lr1y5DklG3bt2Hvi73S83vyzBSdi572H4nV8OD/wbcf0t4PT755BOjUqVKhoeHh+Hs7GwUK1bM+PTTT42YmJgM2598+fIZHTt2tP6c8D7YvXu3Tb/kjsGEetOyrpo1axo1a9a0aZsxY4ZRoEABw97ePtE5eNKkSUaxYsWMzJkzG97e3sY777xjXL16Ncn9BYDnlcUwWK0PAIDnXUREhHLnzq0hQ4Zo8ODBGV3OcyMkJETlypXT/Pnz9frrr2d0OUjGgQMHVLZsWX377bd68803U7RNp06dtHTp0oeu2/c0edb2BwDwZGBNKQAAoDlz5iguLi7FH7iRerdv307UNn78eNnZ2dksWo8nz4wZM+Tq6qrmzZtndCkAADxTWFMKAIDn2MaNG3Xo0CF9+umnatq06UOv4Ib/ZsyYMdq7d69q166tTJky6eeff9bPP/+st956S76+vhldHpKwatUqHTp0SNOnT1fPnj0fup4eAABIPUIpAACeY8OHD9f27dtVrVq1RFeCQ9qqWrWq1q9frxEjRujmzZvKmzevhg4dqoEDB2Z0aUjGe++9p0uXLqlhw4YaNmxYRpcDAMAzhzWlAAAAAAAAYDrWlAIAAAAAAIDpCKUAAAAAAABguuduTan4+HhdvHhRWbNmlcViyehyAAAAAAAAnimGYejGjRvy8fGRnV3y46Geu1Dq4sWLXOEGAAAAAAAgnZ0/f14vvPBCsvc/d6FU1qxZJd17Ydzc3DK4GgAAAAAAgGdLZGSkfH19rRlMcp67UCphyp6bmxuhFAAAAAAAQDp51LJJLHQOAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADDdc7emFAAAAAAAaSkuLk6xsbEZXQZgmsyZM8ve3v4/Pw6hFAAAAAAAj8EwDIWFhenatWsZXQpgOg8PD+XKleuRi5k/DKEUAAAAAACPISGQypkzp7JkyfKfPpwDTwvDMHTr1i2Fh4dLknLnzv3Yj0Uohf9k8uTJ+vzzzxUWFqYyZcpo4sSJqlSpUpJ9Y2NjNWrUKM2dO1cXLlxQ0aJFNXr0aNWvX9/a58aNGxo8eLCWL1+u8PBwlStXThMmTFDFihWtfS5duqR+/frpl19+0bVr11SjRg1NnDhRhQsXliSdOXNG+fPnT7KG7777Tq1atUrDVwAAAADA8yguLs4aSOXIkSOjywFM5ezsLEkKDw9Xzpw5H3sqHwud47EtWbJEvXv3VnBwsPbt26cyZcqoXr161rT0QYMGDdLXX3+tiRMn6tChQ3r77bfVrFkz7d+/39qna9euWr9+vebNm6e//vpLdevWVWBgoC5cuCDpXiLbtGlTnTp1Sj/++KP279+vfPnyKTAwUFFRUZIkX19fhYaG2tyGDRsmV1dXNWjQIP1fGAAAAADPvIQ1pLJkyZLBlQAZI+G9/1/WU7MYhmGkVUFPg8jISLm7u+v69etyc3PL6HKeagEBAapYsaImTZokSYqPj5evr6/ee+899e/fP1F/Hx8fDRw4UD169LC2tWjRQs7Ozpo/f75u376trFmz6scff1SjRo2sffz9/dWgQQN98sknOnbsmIoWLaqDBw+qZMmS1ufNlSuXRo4cqa5duyZZa7ly5VS+fHnNnDkzLV8CAAAAAM+pO3fu6PTp08qfP7+cnJwyuhzAdA87BlKavTBSCo8lJiZGe/fuVWBgoLXNzs5OgYGB2rFjR5LbREdHJ3qjOjs7a+vWrZKku3fvKi4u7qF9oqOjJcmmj52dnRwdHa19HrR3716FhISoS5cuqdxLAAAAAACQXgil8FgiIiIUFxcnb29vm3Zvb2+FhYUluU29evU0btw4HT9+XPHx8Vq/fr2WLVum0NBQSVLWrFlVpUoVjRgxQhcvXlRcXJzmz5+vHTt2WPsUK1ZMefPm1YABA3T16lXFxMRo9OjR+ueff6x9HjRz5kwVL15cVatWTcNXAAAAAACeD7Vq1dIHH3zwnx+nU6dOatq06X9+nEfZvHmzLBbLQ6+KOGfOHHl4eKR7LXg4FjqHaSZMmKBu3bqpWLFislgsKliwoIKCgjRr1ixrn3nz5qlz587KkyeP7O3tVb58ebVr10579+6VJGXOnFnLli1Tly5dlD17dtnb2yswMFANGjRQUjNRb9++rYULF2rw4MGm7ScAAACA59vhYsVNfb7iRw6nqn+nTp00d+5cde/eXdOmTbO5r0ePHpoyZYo6duyoOXPmSJKWLVumzJkz/+c6J0yYkOTntozQpk0bNWzY0Prz0KFDtWLFCoWEhKRo+3/++UcFChRQkSJFdPDgwXSq8tnHSCk8Fk9PT9nb2+vSpUs27ZcuXVKuXLmS3MbLy0srVqxQVFSUzp49qyNHjsjV1VUFChSw9ilYsKB+++033bx5U+fPn9euXbsUGxtr08ff318hISG6du2aQkNDtXbtWv377782fRIsXbpUt27dUocOHdJozwEAAADg6efr66vFixfr9u3b1rY7d+5o4cKFyps3r03f7NmzK2vWrP/5Od3d3Z+Y0UnOzs7KmTPnY28/Z84ctW7dWpGRkdq5c2caVpZ6cXFxio+Pz9AaHhehFB6Lg4OD/P39tWHDBmtbfHy8NmzYoCpVqjx0WycnJ+XJk0d3797VDz/8oNdeey1RHxcXF+XOnVtXr17VunXrkuzj7u4uLy8vHT9+XHv27Emyz8yZM9WkSRN5eXk9xl4CAAAAwLOpfPny8vX11bJly6xty5YtU968eVWuXDmbvg9O35syZYoKFy4sJycneXt7q2XLltb7li5dqlKlSsnZ2Vk5cuSwuVL6g9P3atWqpV69eqlv377Knj27cuXKpaFDh9o895EjR/TSSy/JyclJJUqU0K+//iqLxaIVK1Y8ch+3bdum0qVLy8nJSZUrV7YZ0XT/9L05c+Zo2LBhOnDggCwWiywWi3WUWFIMw9Ds2bP15ptvqn379kleUGvbtm2qVauWsmTJomzZsqlevXq6evWqpHufnceMGaNChQrJ0dFRefPm1aeffiop6amHISEhslgsOnPmjE3tK1euVIkSJeTo6Khz585p9+7dqlOnjjw9PeXu7q6aNWtq3759NnVdu3ZN3bt3l7e3t5ycnPTiiy/qp59+UlRUlNzc3LR06VKb/itWrJCLi4tu3LjxyNf7cRBK4bH17t1bM2bM0Ny5c3X48GG98847ioqKUlBQkCSpQ4cOGjBggLX/zp07tWzZMp06dUq///676tevr/j4ePXt29faZ926dVq7dq1Onz6t9evXq3bt2ipWrJj1MSXp+++/1+bNm3Xq1Cn9+OOPqlOnjpo2baq6deva1HfixAlt2bIl2SvyAQAAPG0mT54sPz8/OTk5KSAgQLt27Uq2b2xsrIYPH66CBQvKyclJZcqU0dq1a236xMXFafDgwcqfP7+cnZ1VsGBBjRgxwjq9JjY2Vv369VOpUqXk4uIiHx8fdejQQRcvXrQ+xpkzZ9SlSxebxwgODlZMTEz6vAgA0kznzp01e/Zs68+zZs2y+eyVlD179qhXr14aPny4jh49qrVr16pGjRqSpNDQULVr106dO3fW4cOHtXnzZjVv3vyhU/bmzp0rFxcX7dy5U2PGjNHw4cO1fv16SffOUU2bNlWWLFm0c+dOTZ8+XQMHDkzx/vXp00djx47V7t275eXlpcaNGys2NjZRvzZt2uijjz5SyZIlFRoaqtDQULVp0ybZx920aZNu3bqlwMBAvfHGG1q8eLE1eJPuhUivvPKKSpQooR07dmjr1q1q3Lix4uLiJEkDBgzQZ599psGDB+vQoUNauHBhovWaH+XWrVsaPXq0vvnmG/3999/KmTOnbty4oY4dO2rr1q36448/VLhwYTVs2NAaKMXHx6tBgwbatm2b5s+fr0OHDumzzz6Tvb29XFxc1LZtW5v3gyTNnj1bLVu2TJORcklhTSk8tjZt2ujy5csaMmSIwsLCVLZsWa1du9Z6MJ07d052dv+fe965c0eDBg3SqVOn5OrqqoYNG2revHk2wzevX7+uAQMG6J9//lH27NnVokULffrppzbzl0NDQ9W7d29dunRJuXPnVocOHZJcM2rWrFl64YUXEoVVAAAAT6MlS5aod+/emjZtmgICAjR+/HjVq1dPR48eTXIKyqBBgzR//nzNmDFDxYoV07p169SsWTNt377dOgpi9OjRmjp1qubOnauSJUtqz549CgoKkru7u3r16qVbt25p3759Gjx4sMqUKaOrV6/q/fffV5MmTbRnzx5J90YxxMfH6+uvv1ahQoV08OBBdevWTVFRUfriiy9MfY0ApM4bb7yhAQMG6OzZs5Luje5ZvHixNm/enOw2586dk4uLi1599VVlzZpV+fLls55TQkNDdffuXTVv3lz58uWTJJUqVeqhNZQuXVrBwcGSpMKFC2vSpEnasGGD6tSpo/Xr1+vkyZPavHmzdZmYTz/9VHXq1EnR/gUHB1v7zp07Vy+88IKWL1+u1q1b2/RzdnaWq6urMmXKlOxyNPebOXOm2rZtK3t7e7344osqUKCAvv/+e3Xq1EmSNGbMGFWoUEFTpkyxblOyZElJ0o0bNzRhwgRNmjRJHTt2lHRvGZuXXnopRfuUIDY2VlOmTFGZMmWsbS+//LJNn+nTp8vDw0O//fabXn31Vf3666/atWuXDh8+rCJFikiSzTI4Xbt2VdWqVRUaGqrcuXMrPDxca9as0a+//pqq2lIjQ0dKbdmyRY0bN5aPj0+Kh99t3rxZ5cuXl6OjowoVKvTQIXVIfz179tTZs2cVHR2tnTt3KiAgwHrf5s2bbX4/NWvW1KFDh3Tnzh1FRETo22+/lY+Pj83jtW7dWidPnlR0dLRCQ0M1adIkubu72/Tp1auXzp8/r5iYGJ09e1YjRoyQg4NDotpGjhyZKBgDAAB4Wo0bN07dunVTUFCQSpQooWnTpilLliw2F42537x58/Txxx+rYcOGKlCggN555x01bNhQY8eOtfbZvn27XnvtNTVq1Eh+fn5q2bKl6tatax2B5e7urvXr16t169YqWrSoKleurEmTJmnv3r06d+6cJKl+/fqaPXu26tatqwIFCqhJkyb63//+ZzMlCMCTycvLS40aNdKcOXM0e/ZsNWrUSJ6eng/dpk6dOsqXL58KFCigN998UwsWLNCtW7ckSWXKlNErr7yiUqVKqVWrVpoxY4Z1ylpySpcubfNzQhgiSUePHpWvr69NUFSpUiWb/g0aNJCrq6tcXV2twU+C+5eWyZ49u4oWLarDh1O3KPyDrl27pmXLlumNN96wtr3xxhs2U/gSRkol5fDhw4qOjk72/pRycHBI9NpdunRJ3bp1U+HCheXu7i43NzfdvHnTer4OCQnRCy+8YA2kHlSpUiWVLFlSc+fOlSTNnz9f+fLls46ESw8Z+mk9KipKZcqU0eTJk1PU//Tp02rUqJFq166tkJAQffDBB+ratavWrVuXzpUCAAAAGScmJkZ79+5VYGCgtc3Ozk6BgYHasWNHkttER0fLycnJps3Z2Vlbt261/ly1alVt2LBBx44dkyQdOHBAW7duVYMGDZKt5fr167JYLA9drPj69evKnj17SnYNQAbr3Lmz5syZo7lz56pz586P7J81a1bt27dPixYtUu7cuTVkyBCVKVNG165dk729vdavX6+ff/5ZJUqU0MSJE1W0aFGdPn062cd78Kp+FoslVYt2f/PNNwoJCVFISIjWrFmT4u0e18KFC3Xnzh0FBAQoU6ZMypQpk/r166etW7daz6XOzs7Jbv+w+yRZB1XcP+UxqSmHzs7OslgsNm0dO3ZUSEiIJkyYoO3btyskJEQ5cuSwTqd+1HNL90ZLJQwumT17toKCghI9T1rK0FCqQYMG+uSTT9SsWbMU9Z82bZry58+vsWPHqnjx4urZs6datmypL7/8Mp0rBQAAADJORESE4uLiEq054u3trbCwsCS3qVevnsaNG6fjx48rPj5e69ev17JlyxQaGmrt079/f7Vt21bFihVT5syZVa5cOX3wwQd6/fXXk3zMO3fuqF+/fmrXrp3c3NyS7HPixAlNnDhR3bt3f8y9BWCm+vXrKyYmRrGxsapXr16KtsmUKZMCAwM1ZswY/fnnnzpz5ow2btwo6V6oVK1aNQ0bNkz79++Xg4ODli9f/li1FS1aVOfPn7e56vvu3btt+uTJk0eFChVSoUKFrFMGE/zxxx/W/7969aqOHTum4sWLJ/lcDg4O1jWfHmbmzJn66KOPrEFYSEiIDhw4oOrVq1tHrpYuXdrmomD3K1y4sJydnZO9P+EiXfefq0NCQh5Zl3Rv+mWvXr3UsGFDlSxZUo6OjoqIiLDeX7p0af3zzz/W8Cwpb7zxhs6ePauvvvpKhw4dsk4xTC9P1ZpSO3bssPl2SLr3j+39VwEAAAAAIE2YMEHdunVTsWLFZLFYVLBgQQUFBdlM9/vuu++0YMECLVy4UCVLlrTORvDx8Un0QSQ2NlatW7eWYRiaOnVqks954cIF1a9fX61atVK3bt3Sdf8ApA17e3vrlDZ7e/tH9v/pp5906tQp1ahRQ9myZdOaNWsUHx+vokWLaufOndqwYYPq1q2rnDlzaufOnbp8+XKyQdCj1KlTRwULFlTHjh01ZswY3bhxQ4MGDZKkFI3eGT58uHLkyCFvb28NHDhQnp6eNlf/u5+fn59Onz5tneKWNWtWOTo62vQJCQnRvn37tGDBAhUrVszmvnbt2mn48OH65JNPNGDAAJUqVUrvvvuu3n77bTk4OGjTpk1q1aqVPD091a9fP/Xt21cODg6qVq2aLl++rL///ltdunRRoUKF5Ovrq6FDh+rTTz/VsWPHbKZdP0zhwoU1b948VahQQZGRkerTp4/N6KiaNWuqRo0aatGihcaNG6dChQrpyJEjslgsql+/viQpW7Zsat68ufr06aO6devqhRdeSNFzP66narGdsLCwJL8dioyM1O3bt5PcJjo6WpGRkTY3AAAA4Gni6ekpe3t7m9EC0r31Q5JblNfLy0srVqxQVFSUzp49qyNHjsjV1dVmUds+ffpYR0uVKlVKb775pj788EONGjXK5rESAqmzZ89q/fr1SY6SunjxomrXrq2qVatq+vTpabDXAMzi5uaW7OjHB3l4eGjZsmV6+eWXVbx4cU2bNk2LFi1SyZIl5ebmpi1btqhhw4YqUqSIBg0apLFjxz50SvDD2Nvba8WKFbp586YqVqyorl27Wq++9+D05KR89tlnev/99+Xv76+wsDCtWrUqyfWIJalFixaqX7++ateuLS8vLy1atChRn5kzZ6pEiRKJAilJatasmXVh8CJFiuiXX37RgQMHVKlSJVWpUkU//vijMmW6Ny5o8ODB+uijjzRkyBAVL15cbdq0sa6jlTlzZi1atEhHjhxR6dKlNXr0aH3yyScper1mzpypq1evqnz58nrzzTfVq1evRBfC+OGHH1SxYkW1a9dOJUqUUN++fRONEOvSpYtiYmJSNJ3zv7IYD7s2o4ksFouWL1+ebGopSUWKFFFQUJAGDBhgbVuzZo0aNWqkW7duJTk/cujQoRo2bFii9uvXr6f4oHuSHS72eIkzzFX8yH9bTA8AACAgIECVKlXSxIkTJd27tHfevHnVs2dP9e/f/5Hbx8bGqnjx4mrdurVGjhwpScqRI4c++eQTvfPOO9Z+o0aN0uzZs63TOxICqePHj2vTpk3WqSX3u3DhgmrXri1/f3/Nnz8/RaMtgKfdnTt3dPr0aeXPnz9FAQnSxrZt2/TSSy/pxIkTKliwYEaX80yaN2+ePvzwQ128eDHZEE96+DEQGRkpd3f3R2YvT9X0vVy5ciX57ZCbm1uyC3YNGDBAvXv3tv4cGRkpX1/fdK0TAAAASGu9e/dWx44dVaFCBVWqVEnjx49XVFSUgoKCJEkdOnRQnjx5rKOcdu7cqQsXLqhs2bK6cOGChg4dqvj4ePXt29f6mI0bN9ann36qvHnzqmTJktq/f7/GjRtn/XY8NjZWLVu21L59+/TTTz8pLi7OuoZV9uzZ5eDgoAsXLqhWrVrKly+fvvjiC12+fNn6+Cm5tDoAPMzy5cvl6uqqwoUL68SJE3r//fdVrVo1Aql0cOvWLYWGhuqzzz5T9+7dHxpIpZWnKpSqUqVKotX0169fb3OZxwc5OjommgcKAAAAPG3atGmjy5cva8iQIQoLC1PZsmW1du1a6/IW586ds161Sbr3DfagQYN06tQpubq6qmHDhpo3b57NVfMmTpyowYMH691331V4eLh8fHzUvXt3DRkyRNK9EVArV66UJJUtW9amnk2bNqlWrVpav369Tpw4oRMnTiRae+QJmZQB4Cl248YN9evXT+fOnZOnp6cCAwNTvMYSUmfMmDH69NNPVaNGDZsZaukpQ6fv3bx5UydOnJAklStXTuPGjVPt2rWVPXt25c2bVwMGDNCFCxf07bffSpJOnz6tF198UT169FDnzp21ceNG9erVS6tXr07xVQJSOoTsacH0vacD0/cAAACAZwvT9/C8S4vpexm60PmePXtUrlw5lStXTtK9IcnlypWzfjMTGhqqc+fOWfvnz59fq1ev1vr161WmTBmNHTtW33zzTYoDKQAAAAAAADwZMnT6Xq1atR46pHfOnDlJbrN///50rAoAAAAAAADpLUNHSgEAAAAA8DSLj4/P6BKADJEW7/2naqFzAAAAAACeBA4ODrKzs9PFixfl5eUlBwcHWSyWjC4LSHeGYSgmJkaXL1+WnZ3df7pKH6EUAAAAkEJcZObpwYVmkN7s7OyUP39+hYaG6uLFixldDmC6LFmyKG/evDZXfk0tQikAAAAAAB6Dg4OD8ubNq7t37youLi6jywFMY29vr0yZMv3n0YGEUgAAAAAAPCaLxaLMmTMrc+bMGV0K8NRhoXMAAAAAAACYjlAKAAAAAAAApiOUAgA8lyZPniw/Pz85OTkpICBAu3btSrZvbGyshg8froIFC8rJyUllypTR2rVrbfpMnTpVpUuXlpubm9zc3FSlShX9/PPPNn1OnjypZs2aycvLS25ubmrdurUuXbpkvX/z5s2yWCxJ3nbv3p22LwAAAACQwQilAADPnSVLlqh3794KDg7Wvn37VKZMGdWrV0/h4eFJ9h80aJC+/vprTZw4UYcOHdLbb7+tZs2aaf/+/dY+L7zwgj777DPt3btXe/bs0csvv6zXXntNf//9tyQpKipKdevWlcVi0caNG7Vt2zbFxMSocePGio+PlyRVrVpVoaGhNreuXbsqf/78qlChQvq/MAAAAICJLIZhGBldhJkiIyPl7u6u69evy83NLaPL+c+4LPHTgUsSA0+WgIAAVaxYUZMmTZIkxcfHy9fXV++995769++fqL+Pj48GDhyoHj16WNtatGghZ2dnzZ8/P9nnyZ49uz7//HN16dJFv/zyixo0aKCrV69a//25fv26smXLpl9++UWBgYGJto+NjVWePHn03nvvafDgwf91twGkAf72enrw9xcAZJyUZi+MlAIAPFdiYmK0d+9emxDIzs5OgYGB2rFjR5LbREdHy8nJyabN2dlZW7duTbJ/XFycFi9erKioKFWpUsX6GBaLRY6OjtZ+Tk5OsrOzS/ZxVq5cqX///VdBQUGp2kcAAADgaUAoBQB4rkRERCguLk7e3t427d7e3goLC0tym3r16mncuHE6fvy44uPjtX79ei1btkyhoaE2/f766y+5urrK0dFRb7/9tpYvX64SJUpIkipXriwXFxf169dPt27dUlRUlP73v/8pLi4u0eMkmDlzpurVq6cXXnghDfYcAAAAeLIQSgEA8AgTJkxQ4cKFVaxYMTk4OKhnz54KCgqSnZ3tP6NFixZVSEiIdu7cqXfeeUcdO3bUoUOHJEleXl76/vvvtWrVKrm6usrd3V3Xrl1T+fLlEz2OJP3zzz9at26dunTpYso+AgAAAGbLlNEFAABgJk9PT9nb29tc9U6SLl26pFy5ciW5jZeXl1asWKE7d+7o33//lY+Pj/r3768CBQrY9HNwcFChQoUkSf7+/tq9e7cmTJigr7/+WpJUt25dnTx5UhEREcqUKZM8PDyUK1euRI8jSbNnz1aOHDnUpEmTtNhtAAAA4InDSCkAwHPFwcFB/v7+2rBhg7UtPj5eGzZssK7/lBwnJyflyZNHd+/e1Q8//KDXXnvtof3j4+MVHR2dqN3T01MeHh7auHGjwsPDEwVPhmFo9uzZ6tChgzJnzpyKvQMAAACeHoyUAgA8d3r37q2OHTuqQoUKqlSpksaPH6+oqCjrguIdOnRQnjx5NGrUKEnSzp07deHCBZUtW1YXLlzQ0KFDFR8fr759+1ofc8CAAWrQoIHy5s2rGzduaOHChdq8ebPWrVtn7TN79mwVL15cXl5e2rFjh95//319+OGHKlq0qE19Gzdu1OnTp9W1a1cTXg0AAAAgYxBKAQCeO23atNHly5c1ZMgQhYWFqWzZslq7dq118fNz587ZrPN0584dDRo0SKdOnZKrq6saNmyoefPmycPDw9onPDxcHTp0UGhoqNzd3VW6dGmtW7dOderUsfY5evSoBgwYoCtXrsjPz08DBw7Uhx9+mKi+mTNnqmrVqipWrFj6vQgAAABABrMYhmFkdBFmioyMlLu7u65fvy43N7eMLuc/O1yseEaXgBQofuRwRpcAAADSAH97PT34+wsAMk5KsxfWlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKbj6nsAgAzBYsFPBxYKBgAAQHphpBQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMl+Gh1OTJk+Xn5ycnJycFBARo165dD+0/fvx4FS1aVM7OzvL19dWHH36oO3fumFQtAAAAAAAA0kKGhlJLlixR7969FRwcrH379qlMmTKqV6+ewsPDk+y/cOFC9e/fX8HBwTp8+LBmzpypJUuW6OOPPza5cgAAAAAAAPwXGRpKjRs3Tt26dVNQUJBKlCihadOmKUuWLJo1a1aS/bdv365q1aqpffv28vPzU926ddWuXbtHjq4CAAAAAADAkyXDQqmYmBjt3btXgYGB/1+MnZ0CAwO1Y8eOJLepWrWq9u7daw2hTp06pTVr1qhhw4bJPk90dLQiIyNtbgAAAAAAAMhYmTLqiSMiIhQXFydvb2+bdm9vbx05ciTJbdq3b6+IiAi99NJLMgxDd+/e1dtvv/3Q6XujRo3SsGHD0rR2AAAAAAAA/DcZvtB5amzevFkjR47UlClTtG/fPi1btkyrV6/WiBEjkt1mwIABun79uvV2/vx5EysGAAAAAABAUjJspJSnp6fs7e116dIlm/ZLly4pV65cSW4zePBgvfnmm+rataskqVSpUoqKitJbb72lgQMHys4uccbm6OgoR0fHtN8BAAAAAAAAPLYMGynl4OAgf39/bdiwwdoWHx+vDRs2qEqVKkluc+vWrUTBk729vSTJMIz0KxYAAAAAAABpKsNGSklS79691bFjR1WoUEGVKlXS+PHjFRUVpaCgIElShw4dlCdPHo0aNUqS1LhxY40bN07lypVTQECATpw4ocGDB6tx48bWcAoAAAAAAABPvgwNpdq0aaPLly9ryJAhCgsLU9myZbV27Vrr4ufnzp2zGRk1aNAgWSwWDRo0SBcuXJCXl5caN26sTz/9NKN2AQAAAAAAAI/BYjxn894iIyPl7u6u69evy83NLaPL+c8OFyue0SUgBYofOZzRJQBPHM5fTwfOX4Atzl1PD85fAJBxUpq9PFVX3wMAAAAAAMCzgVAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAA6Wry5Mny8/OTk5OTAgICtGvXrmT71qpVSxaLJdGtUaNGkqTY2Fj169dPpUqVkouLi3x8fNShQwddvHjR5nGaNGmivHnzysnJSblz59abb75p0+fOnTvq1KmTSpUqpUyZMqlp06bpsu9IHqEUAAAAAABIN0uWLFHv3r0VHBysffv2qUyZMqpXr57Cw8OT7L9s2TKFhoZabwcPHpS9vb1atWolSbp165b27dunwYMHa9++fVq2bJmOHj2qJk2a2DxO7dq19d133+no0aP64YcfdPLkSbVs2dJ6f1xcnJydndWrVy8FBgam3wuAZFkMwzAyuggzRUZGyt3dXdevX5ebm1tGl/OfHS5WPKNLQAoUP3I4o0sAnjicv54OnL8AW5y7nh6cv4AnR0BAgCpWrKhJkyZJkuLj4+Xr66v33ntP/fv3f+T248eP15AhQxQaGioXF5ck++zevVuVKlXS2bNnlTdv3iT7rFy5Uk2bNlV0dLQyZ85sc1+nTp107do1rVixInU7hySlNHthpBQAAAAAAEgXMTEx2rt3r81IJDs7OwUGBmrHjh0peoyZM2eqbdu2yQZSknT9+nVZLBZ5eHgkef+VK1e0YMECVa1aNVEghYxDKAUAAAAAANJFRESE4uLi5O3tbdPu7e2tsLCwR26/a9cuHTx4UF27dk22z507d9SvXz+1a9cu0aicfv36ycXFRTly5NC5c+f0448/Pt6OIF0QSgEAAAAAgCfSzJkzVapUKVWqVCnJ+2NjY9W6dWsZhqGpU6cmur9Pnz7av3+/fvnlF9nb26tDhw56zlYxeqJlyugCAAAAAADAs8nT01P29va6dOmSTfulS5eUK1euh24bFRWlxYsXa/jw4UnenxBInT17Vhs3bkxy7SJPT095enqqSJEiKl68uHx9ffXHH3+oSpUqj79TSDOMlAIAAAAAAOnCwcFB/v7+2rBhg7UtPj5eGzZseGQw9P333ys6OlpvvPFGovsSAqnjx4/r119/VY4cOR5ZS3x8vCQpOjo6lXuB9MJIKQAAAAAAkG569+6tjh07qkKFCqpUqZLGjx+vqKgoBQUFSZI6dOigPHnyaNSoUTbbzZw5U02bNk0UOMXGxqply5bat2+ffvrpJ8XFxVnXp8qePbscHBy0c+dO7d69Wy+99JKyZcumkydPavDgwSpYsKBNGHbo0CHFxMToypUrunHjhkJCQiRJZcuWTb8XBFaEUgAAAAAAIN20adNGly9f1pAhQxQWFqayZctq7dq11sXPz507Jzs724lcR48e1datW/XLL78kerwLFy5o5cqVkhKHR5s2bVKtWrWUJUsWLVu2TMHBwYqKilLu3LlVv359DRo0SI6Ojtb+DRs21NmzZ60/lytXTpJYd8okFuM5e6UjIyPl7u6u69evJznf9GlzuFjxjC4BKVD8yOGMLgF44nD+ejpw/gJsce56enD+AoCMk9LshTWlAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYLpMGV0AAAAAAABIX1w99OnwvF05lJFSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdBkeSk2ePFl+fn5ycnJSQECAdu3a9dD+165dU48ePZQ7d245OjqqSJEiWrNmjUnVAgAAAAAAIC1kysgnX7JkiXr37q1p06YpICBA48ePV7169XT06FHlzJkzUf+YmBjVqVNHOXPm1NKlS5UnTx6dPXtWHh4e5hcPAAAAAACAx5ahodS4cePUrVs3BQUFSZKmTZum1atXa9asWerfv3+i/rNmzdKVK1e0fft2Zc6cWZLk5+dnZskAAAAAAABIAxk2fS8mJkZ79+5VYGDg/xdjZ6fAwEDt2LEjyW1WrlypKlWqqEePHvL29taLL76okSNHKi4uzqyyAQAAAAAAkAYybKRURESE4uLi5O3tbdPu7e2tI0eOJLnNqVOntHHjRr3++utas2aNTpw4oXfffVexsbEKDg5Ocpvo6GhFR0dbf46MjEy7nQAAAAAAAMBjyfCFzlMjPj5eOXPm1PTp0+Xv7682bdpo4MCBmjZtWrLbjBo1Su7u7tabr6+viRUDAAAAAAAgKRkWSnl6esre3l6XLl2yab906ZJy5cqV5Da5c+dWkSJFZG9vb20rXry4wsLCFBMTk+Q2AwYM0PXr16238+fPp91OAAAAAAAA4LFkWCjl4OAgf39/bdiwwdoWHx+vDRs2qEqVKkluU61aNZ04cULx8fHWtmPHjil37txycHBIchtHR0e5ubnZ3AAAAAAAAJCxMnT6Xu/evTVjxgzNnTtXhw8f1jvvvKOoqCjr1fg6dOigAQMGWPu/8847unLlit5//30dO3ZMq1ev1siRI9WjR4+M2gUAAAAAAAA8hgxb6FyS2rRpo8uXL2vIkCEKCwtT2bJltXbtWuvi5+fOnZOd3f/nZr6+vlq3bp0+/PBDlS5dWnny5NH777+vfv36ZdQuAAAAAAAA4DFkaCglST179lTPnj2TvG/z5s2J2qpUqaI//vgjnasCAAAAAABAekr19D0/Pz8NHz5c586dS496AAAAAAAA8BxIdSj1wQcfaNmyZSpQoIDq1KmjxYsXKzo6Oj1qAwAAAAAAwDPqsUKpkJAQ7dq1S8WLF9d7772n3Llzq2fPntq3b1961AgAAAAAAIBnzGNffa98+fL66quvdPHiRQUHB+ubb75RxYoVVbZsWc2aNUuGYaRlnQAAAAAAAHiGPPZC57GxsVq+fLlmz56t9evXq3LlyurSpYv++ecfffzxx/r111+1cOHCtKwVAAAAAAAAz4hUh1L79u3T7NmztWjRItnZ2alDhw768ssvVaxYMWufZs2aqWLFimlaKAAAAAAAAJ4dqQ6lKlasqDp16mjq1Klq2rSpMmfOnKhP/vz51bZt2zQpEAAAAAAAAM+eVIdSp06dUr58+R7ax8XFRbNnz37sogAAAAAAAPBsS/VC5+Hh4dq5c2ei9p07d2rPnj1pUhQAAAAAAACebakOpXr06KHz588nar9w4YJ69OiRJkUBAAAAAADg2ZbqUOrQoUMqX758ovZy5crp0KFDaVIUAAAAAAAAnm2pDqUcHR116dKlRO2hoaHKlCnVS1QBAAAAAADgOZTqUKpu3boaMGCArl+/bm27du2aPv74Y9WpUydNiwMAAAAAAMCzKdVDm7744gvVqFFD+fLlU7ly5SRJISEh8vb21rx589K8QAAAAAAAADx7Uh1K5cmTR3/++acWLFigAwcOyNnZWUFBQWrXrp0yZ86cHjUCAAAAAADgGfNYi0C5uLjorbfeSutaAAAAAAAA8Jx47JXJDx06pHPnzikmJsamvUmTJv+5KAAAAAAAADzbUh1KnTp1Ss2aNdNff/0li8UiwzAkSRaLRZIUFxeXthUCAAAAAADgmZPqq++9//77yp8/v8LDw5UlSxb9/fff2rJliypUqKDNmzenQ4kAAAAAAAB41qR6pNSOHTu0ceNGeXp6ys7OTnZ2dnrppZc0atQo9erVS/v370+POgEAAAAAAPAMSfVIqbi4OGXNmlWS5OnpqYsXL0qS8uXLp6NHj6ZtdQAAAAAAAHgmpXqk1IsvvqgDBw4of/78CggI0JgxY+Tg4KDp06erQIEC6VEjAAAAAAAAnjGpDqUGDRqkqKgoSdLw4cP16quvqnr16sqRI4eWLFmS5gUCAAAAAADg2ZPqUKpevXrW/y9UqJCOHDmiK1euKFu2bNYr8AEAAAAAAAAPk6o1pWJjY5UpUyYdPHjQpj179uwEUgAAAAAAAEixVIVSmTNnVt68eRUXF5de9QAAAAAAAOA5kOqr7w0cOFAff/yxrly5kh71AAAAAAAA4DmQ6jWlJk2apBMnTsjHx0f58uWTi4uLzf379u1Ls+IAAAAAAADwbEp1KNW0adN0KAMAAAAAAADPk1SHUsHBwelRBwAAAAAAAJ4jqV5TCgAAAAAAAPivUj1Sys7OThaLJdn7uTIfAAAAAAAAHiXVodTy5cttfo6NjdX+/fs1d+5cDRs2LM0KAwAAAAAAwLMr1aHUa6+9lqitZcuWKlmypJYsWaIuXbqkSWEAAAAAAAB4dqXZmlKVK1fWhg0b0urhAAAAAAAA8AxLk1Dq9u3b+uqrr5QnT560eDgAAAAAAAA841I9fS9btmw2C50bhqEbN24oS5Ysmj9/fpoWBwAAAAAAgGdTqkOpL7/80iaUsrOzk5eXlwICApQtW7Y0LQ4AAAAAAADPplSHUp06dUqHMgAAAAAAAPA8SfWaUrNnz9b333+fqP3777/X3Llz06QoAAAAAAAAPNtSHUqNGjVKnp6eidpz5sypkSNHpklRAAAAAAAAeLalOpQ6d+6c8ufPn6g9X758OnfuXJoUBQAAAAAAgGdbqkOpnDlz6s8//0zUfuDAAeXIkSNNigIAAAAAAMCzLdWhVLt27dSrVy9t2rRJcXFxiouL08aNG/X++++rbdu26VEjAAAAAAAAnjGpvvreiBEjdObMGb3yyivKlOne5vHx8erQoQNrSgEAAAAAACBFUh1KOTg4aMmSJfrkk08UEhIiZ2dnlSpVSvny5UuP+gAAAAAAAPAMSnUolaBw4cIqXLhwWtYCAAAAAACA50Sq15Rq0aKFRo8enah9zJgxatWqVZoUBQAAAAAAgGdbqkOpLVu2qGHDhonaGzRooC1btqRJUQAAAAAAAHi2pTqUunnzphwcHBK1Z86cWZGRkWlSFAAAAAAAAJ5tqQ6lSpUqpSVLliRqX7x4sUqUKJEmRQEAAAAAAODZluqFzgcPHqzmzZvr5MmTevnllyVJGzZs0MKFC7V06dI0LxAAAAAAAADPnlSHUo0bN9aKFSs0cuRILV26VM7OzipTpow2btyo7Nmzp0eNAAAAAAAAeMakOpSSpEaNGqlRo0aSpMjISC1atEj/+9//tHfvXsXFxaVpgQAAAAAAAHj2pHpNqQRbtmxRx44d5ePjo7Fjx+rll1/WH3/8kZa1AQAAAAAA4BmVqpFSYWFhmjNnjmbOnKnIyEi1bt1a0dHRWrFiBYucAwAAAAAAIMVSPFKqcePGKlq0qP7880+NHz9eFy9e1MSJE9OzNgAAAAAAADyjUjxS6ueff1avXr30zjvvqHDhwulZEwAAAAAAAJ5xKR4ptXXrVt24cUP+/v4KCAjQpEmTFBERkZ61AQAAAAAA4BmV4lCqcuXKmjFjhkJDQ9W9e3ctXrxYPj4+io+P1/r163Xjxo30rBMAAAAAAADPkFRffc/FxUWdO3fW1q1b9ddff+mjjz7SZ599ppw5c6pJkybpUSMAAAAAAACeMakOpe5XtGhRjRkzRv/8848WLVqUVjUBAAAAAADgGfefQqkE9vb2atq0qVauXJkWDwcAAAAAAIBnXJqEUgAAAAAAAEBqEEoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTPRGh1OTJk+Xn5ycnJycFBARo165dKdpu8eLFslgsatq0afoWCAAAAAAAgDSV4aHUkiVL1Lt3bwUHB2vfvn0qU6aM6tWrp/Dw8Idud+bMGf3vf/9T9erVTaoUAAAAAAAAaSXDQ6lx48apW7duCgoKUokSJTRt2jRlyZJFs2bNSnabuLg4vf766xo2bJgKFChgYrUAAAAAAABICxkaSsXExGjv3r0KDAy0ttnZ2SkwMFA7duxIdrvhw4crZ86c6tKlixllAgAAAAAAII1lysgnj4iIUFxcnLy9vW3avb29deTIkSS32bp1q2bOnKmQkJAUPUd0dLSio6OtP0dGRj52vQAAAAAAAEgbGT59LzVu3LihN998UzNmzJCnp2eKthk1apTc3d2tN19f33SuEgAAAAAAAI+SoSOlPD09ZW9vr0uXLtm0X7p0Sbly5UrU/+TJkzpz5owaN25sbYuPj5ckZcqUSUePHlXBggVtthkwYIB69+5t/TkyMpJgCgAAAAAAIINlaCjl4OAgf39/bdiwQU2bNpV0L2TasGGDevbsmah/sWLF9Ndff9m0DRo0SDdu3NCECROSDJscHR3l6OiYLvUDAAAAAADg8WRoKCVJvXv3VseOHVWhQgVVqlRJ48ePV1RUlIKCgiRJHTp0UJ48eTRq1Cg5OTnpxRdftNnew8NDkhK1AwAAAAAA4MmV4aFUmzZtdPnyZQ0ZMkRhYWEqW7as1q5da138/Ny5c7Kze6qWvgIAAAAAAMAjZHgoJUk9e/ZMcrqeJG3evPmh286ZMyftCwIAAAAAAEC6YggSAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAw3RMRSk2ePFl+fn5ycnJSQECAdu3alWzfGTNmqHr16sqWLZuyZcumwMDAh/YHAAAAAADAkyfDQ6klS5aod+/eCg4O1r59+1SmTBnVq1dP4eHhSfbfvHmz2rVrp02bNmnHjh3y9fVV3bp1deHCBZMrBwAAAAAAwOPK8FBq3Lhx6tatm4KCglSiRAlNmzZNWbJk0axZs5Lsv2DBAr377rsqW7asihUrpm+++Ubx8fHasGGDyZUDAAAAAADgcWVoKBUTE6O9e/cqMDDQ2mZnZ6fAwEDt2LEjRY9x69YtxcbGKnv27EneHx0drcjISJsbAAAAAAAAMlaGhlIRERGKi4uTt7e3Tbu3t7fCwsJS9Bj9+vWTj4+PTbB1v1GjRsnd3d168/X1/c91AwAAAAAA4L/J8Ol7/8Vnn32mxYsXa/ny5XJyckqyz4ABA3T9+nXr7fz58yZXCQAAAAAAgAdlysgn9/T0lL29vS5dumTTfunSJeXKleuh237xxRf67LPP9Ouvv6p06dLJ9nN0dJSjo2Oa1AsAAAAAAIC0kaEjpRwcHOTv72+zSHnCouVVqlRJdrsxY8ZoxIgRWrt2rSpUqGBGqQAAAAAAAEhDGTpSSpJ69+6tjh07qkKFCqpUqZLGjx+vqKgoBQUFSZI6dOigPHnyaNSoUZKk0aNHa8iQIVq4cKH8/Pysa0+5urrK1dU1w/YDAAAAAAAAKZfhoVSbNm10+fJlDRkyRGFhYSpbtqzWrl1rXfz83LlzsrP7/wFdU6dOVUxMjFq2bGnzOMHBwRo6dKiZpQMAAAAAAOAxZXgoJUk9e/ZUz549k7xv8+bNNj+fOXMm/QsCAAAAAABAunqqr74HAAAAAACApxOhFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTPRGh1OTJk+Xn5ycnJycFBARo165dD+3//fffq1ixYnJyclKpUqW0Zs0akyoFAAAAAABAWsjwUGrJkiXq3bu3goODtW/fPpUpU0b16tVTeHh4kv23b9+udu3aqUuXLtq/f7+aNm2qpk2b6uDBgyZXDgAAAAAAgMeV4aHUuHHj1K1bNwUFBalEiRKaNm2asmTJolmzZiXZf8KECapfv7769Omj4sWLa8SIESpfvrwmTZpkcuUAAAAAAAB4XBkaSsXExGjv3r0KDAy0ttnZ2SkwMFA7duxIcpsdO3bY9JekevXqJdsfAAAAAAAAT55MGfnkERERiouLk7e3t027t7e3jhw5kuQ2YWFhSfYPCwtLsn90dLSio6OtP1+/fl2SFBkZ+V9Kf2LcjIvL6BKQAs/K+w1IS5y/ng6cvwBbnLueHpy/AFucv54Oz8q5K2E/DMN4aL8MDaXMMGrUKA0bNixRu6+vbwZUg+eWu3tGVwAAj4fzF4CnFecvAE+jZ+zcdePGDbk/ZJ8yNJTy9PSUvb29Ll26ZNN+6dIl5cqVK8ltcuXKlar+AwYMUO/eva0/x8fH68qVK8qRI4csFst/3IOMFRkZKV9fX50/f15ubm4ZXQ4ApBjnLwBPI85dAJ5WnL9gNsMwdOPGDfn4+Dy0X4aGUg4ODvL399eGDRvUtGlTSfdCow0bNqhnz55JblOlShVt2LBBH3zwgbVt/fr1qlKlSpL9HR0d5ejoaNPm4eGRFuU/Mdzc3DixAHgqcf4C8DTi3AXgacX5C2Z62AipBBk+fa93797q2LGjKlSooEqVKmn8+PGKiopSUFCQJKlDhw7KkyePRo0aJUl6//33VbNmTY0dO1aNGjXS4sWLtWfPHk2fPj0jdwMAAAAAAACpkOGhVJs2bXT58mUNGTJEYWFhKlu2rNauXWtdzPzcuXOys/v/iwRWrVpVCxcu1KBBg/Txxx+rcOHCWrFihV588cWM2gUAAAAAAACkUoaHUpLUs2fPZKfrbd68OVFbq1at1KpVq3Su6snn6Oio4ODgRNMTAeBJx/kLwNOIcxeApxXnLzypLMajrs8HAAAAAAAApDG7R3cBAAAAAAAA0hahFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAT7nDhw9r7ty5kiSWjAXwNDl48KBWrlwpSYqPj8/gamA2QilkiLi4OFWqVElr167lDycAT5V///1XVatW1e7duzO6FACw+ueffzRkyBD98MMPslgsGV0OAKRIXFycQkJC1LNnT+3atUt2dkQUzxt+4zBdfHy87O3t9cYbb2jy5Mn69ttvJfGtHoCnQ44cOVSzZk199tlnWrdunSS+1QNgPsMwFBcXZ/25Tp06Cg4O1uDBg7V///4MrAwAHs4wDOvfTgmfC9u1a6f+/fvr+PHjGVwdzGYxSAJggoQ/muzt7W3aR48erRkzZmjbtm3y9vbOiNIAIFkP/tGU4Nq1a/rkk0+0ceNG7du3L6PKA/Acio+Pl8ViSXY0VNOmTWUYhmbOnClPT0+TqwOA5CV1/jIMQxaLRVevXlXz5s2VP39+zZo1KwOrhNkYKQVT2NvbWz/Q3bhxw9req1cvZc2aVePHj2ekAQDTpPT7GIvFYnP+un37tiTJw8NDgwYN0pkzZzR9+nRGegJIF/Hx8TajoSTJzs5OFotF58+f17Rp0/TVV1/pwoUL1vs/+OADnT592ro+CwBkhEedv2bMmKHZs2fr5s2bkqRs2bKpV69eWr9+vTZu3JgRJSODEEoh1WJjY7Vt2zZJ/z9lJT4+Xnfv3k0yWLp69aqmTJmimjVrqmjRovr6668VHR0tSXJ2dlarVq30+++/KyQkxLR9APB8iomJ0Z49e2SxWKx/KD3s/BUREaGJEyeqdu3aKlWqlH744QfdvXtX0r1gqmXLlvrpp5904sQJU/cDwLPj/PnzqlatmpYtWybpXmieEHTb2dklGmV+/vx51a9fX6VKldL06dN16tQpnT9/3np/tWrVVKBAAW3atMl6vgKA9HDgwAE1aNBAGzZskPTo89fRo0dVo0YNlSxZUtOmTdNff/2lixcvWu9v1KiRcuTIoY0bNzJg4TmSKaMLwNNn+vTpmjJliv7++2/rQnR2dnbW/4+MjFRkZKRy584te3t7DR48WNu2bVOLFi1UtmxZOTs769atW3J0dJQk1ahRQ2vWrNGvv/6q8uXLZ9h+AXi2xcTEKDg4WFu3btXvv/9u/UPpwfNXTEyMPD09FRcXpw8//FAHDx5Uy5YtVaRIEeXKlUt37tyRq6urJKlevXoaO3asdu7cqcKFC2fYvgF4erm4uKhPnz6qXr26JNlMa9m8ebNWrVqlGzduqE+fPipcuLAWLlyomzdv6s8//1TevHkVFRWlTJnu/UkfHx+vzJkzq3z58tq4caOOHj2qkiVLZsh+AXh2JUy5y5o1q7p16yZ/f39Jic9fa9asUUxMjIYOHaqsWbNq6tSpcnd319GjR5U7d25duXLF+jdVfHy8HBwc5O/vr7///lsXLlyQr69vhuwfzMVIKaRa9+7d9ffff9u0nT9/Xv369VOhQoVUoEABTZs2TTdu3NDu3bu1efNm9evXT4MGDdKrr76qV155RdmyZbOOUihSpIh8fX31119/ZcTuAHhOODg4KDg4WL///rtN+6lTp9S7d28VLlxYRYsW1bfffqv4+HitWbNGu3fv1oQJEzRw4EC1atVK1atXl6urq/X8Vb58eWXJkkXHjh3LiF0C8BSKj4+3GQGQPXt2NW3aVDly5LC2RUREqG7dunr99dd19uxZeXl56d9//5Ukbdy4Ufnz51fmzJl19uxZxcbGWr/oS/hAWLRoUcXExOjSpUsm7hmAZ13C+SvhXFOgQAE1b95cHh4e1j5nzpxRtWrV1L59e506dUqZMmVSaGio7O3t9dNPP6lYsWJycXHRuXPn5OrqKgcHB0n/v7RCmTJldPHiRUVFRZm+f8gYjJRCshIW+E2Y+5sgU6ZMOn78uP79919VrlxZcXFxmjp1qjZv3qxRo0apcOHCiouLk4uLixwdHeXh4aGVK1fq0qVLcnFxUaFChVSwYEFr8p0zZ05lyZJFd+/e1Z07d+Tk5JRRuwzgGZFwVSp7e3ub85eTk5OOHTumO3fuqHTp0rpx44a++OIL/fnnnxo5cqR8fX2tI6eyZcsmi8WiFStW6NChQ3Jzc1PhwoWVP39+6+LB+fPnV1xcnHUKYMJoBQBIkDCiIEFSlzvfvXu3WrdurU2bNsnPz0+TJ09WVFSUtm/frnz58unu3bvWD2ydO3fWqFGjVLRoUb300kuKjY2Vg4ODBgwYoJdeekmSVKxYMZ09e1bZs2c3ZycBPJNScv5avXq1Ro4cqe+//14+Pj4aOXKkXFxcdOjQIXl4eOj27dvWv4969eql8ePHa+7cuapSpYru3LkjT09PDR061DrivHz58ho8eLBy5sxpzk4iw/HXM6we/BCXsMCvJEVFRcnFxUWSdPfuXQ0aNEh79+7ViRMndPToUX333Xfq37+/WrVqZfOYpUuX1pAhQzR06FDdunVL9vb2Wr9+vYoUKaLvvvtOBQoUkCTduXNHjo6OSZ7oAOBREr65S/ijx2KxWP//9u3bcnZ2lnRv9ME777yj6Ohobd26VYcPH9b8+fP1448/qnbt2jaPWa1aNfXt21fjx4/X6dOnFRsbq19++UWNGzfWxIkT5ePjY33umJgYAikAkv7/237DMBJ9sXf37l2tWbNG27Zt06uvvqpKlSpZ//5JuO/dd99VaGioYmJidPHiRV28eFHZs2eXn5+fJKlly5YqV66coqKidOrUKYWFhemXX35R3759tX37dklSvnz5FB4eLnd3d9P3H8DTKyGESmpgQmxsrNasWaOQkBA1a9ZMJUuWlL29vaKjoxUREaEtW7aobdu2ioiIUFxcnCIiInT06FH5+PgoT548kqS33npLtWrV0s2bN3Xy5EmFhYVp+fLlGjZsmObPny/p3oLnkpK9wiiePSQAz7n7L3ee8CEu4QQQGxurIUOGKHfu3KpTp45mzpwp6d6V9Jo1a6bw8HDdvXtXxYoVU+7cufXtt9+qW7duCg4O1vTp07V161bFxsaqbt262r59u+bNm6cZM2Zo586dioiI0A8//GCtI3fu3IqIiJCDgwOL2gFIkfvPX3Z2djahUFRUlHr37i1fX181bdpUP/30kyQpa9asqlevnnVRYH9/f7m5uWnChAnq1auXPvvsMy1YsEAHDhyQxWJRUFCQDhw4oOnTp2vevHlavXq1/vrrL/3yyy/W5ypYsKCuXLlirQnAsyc1x3bCF3sJX7Tt3LlTe/fulSRNmzZNgwcP1pYtW9SpUyd9+eWXkqQXXnhBlSpV0urVqyVJPXr0UI4cORQYGKjg4GB17txZBQsW1JIlS2Rvb68iRYqoXLlyatGihXr06KE8efIoU6ZM1il+J06cULVq1XTr1q20fBkAPKVS+vkq4XNgwvlrz549Onr0qCTp008/1cCBA7V8+XK9/vrr+vbbbyXdG5lZoEABbdmyRZL00UcfKSIiQv7+/ho6dKhatGihEiVKaOvWrXJyclLp0qVVtWpVvfnmm+rTp491WZeEK7QfPnxYtWvXtl6VD88+vtZ9xiQ35S45CX84SdLx48c1YcIEnT9/Xh06dFDu3LkVHh6uyZMn648//lC3bt1Urlw5lS9fXuXKlVNMTIx+++03vfLKK5o0aZKmT58ui8WisLAwzZs3Ty4uLhowYIDat2+vS5cuydPTU/b29tqyZYuyZ8+uEiVKSLo3SurmzZsqU6aMpKSHhQJ4fjw4VDw595+/Dh48qGnTpunq1avq3r27bt++rTt37ujLL7/U8uXL1bZtWx07dkw+Pj4qXbq0rl27ppCQEJUtW1Zz5szRt99+q+joaB08eFDjxo1TkSJFFBwcrDp16ujSpUvy9vaWJP3zzz9yc3NT8eLFJd27uuiVK1fUsmVLa00Anh0J56PUHNv//vuv9u/fr9u3b2vEiBE6cOCAihcvrty5c6tQoULasGGDsmTJohEjRmjChAnq27evcuTIoYCAAGtIVapUKX333XeKjY21fiCcO3euxo0bp5deeklHjhyxjoTauHGjtmzZomHDhlnXpdq1a5ecnJxY5ByApJR/vgoPD9fBgwd1+/Ztffjhhzp37pz8/f3l4+OjnDlzat++fbp69ar69u2rMWPGKCgoSHnz5lWRIkW0e/duSfdGmm/atEk3b97UiRMnlClTJo0cOVKff/65ihUrpt27d+vWrVtyc3PTzz//rH/++Udjx45V1qxZJUl///234uPj5evra/1ci2ecgadefHx8ku0xMTGP3DY2Ntb48MMPjT59+hidO3c22rVrZ7zxxhuGi4uLUaRIEWPTpk3Wvv7+/kb37t2N2NhY49atW0b58uWNDz74IMlaLl++bNSsWdN45513jNu3bxtvvfWW0bFjR6N48eKGl5eX0b9/f5vtatWqZezduzeVew7gaZfc+Ss0NNT466+/DMMwjLi4uCT7xMTEGK+//rrxxRdfGG3btjVat25tNGjQwMiRI4dRunRp6znlypUrRoECBYxPPvnEMAzDOHbsmFGyZElj5MiRNo93584dwzAM48SJE0bp0qWNzz//3Lh27ZrRtm1bo2vXrkaxYsWMXLlyGaNGjbLZrmzZssaJEyce/0UA8ES7e/eusX79emP+/PlGeHi4YRhJn7sS2n788UfDYrEYNWrUMJYsWWJcvnzZGDNmjGGxWIzPP//c2v/cuXOGvb299W+tdevWGW5ubkZISEiixzQMw+jdu7dRrVo14+bNm8aqVauMgIAAw8/Pz2jYsKGxbNkyIyYmxnq+3Lp1q/H111+n+WsB4OkTHx9vfPHFF0a1atWMbdu2GYaR+G+rhHPNvHnzDIvFYjRp0sRYs2aNce7cOeO9994zLBaLsXjxYmv/LVu2GBaLxTh9+rRhGIYxdepUo2jRosbRo0eTrKFdu3ZGo0aNjLi4OOPbb781ihUrZvj6+hqNGjUyVq1aZcTGxlprWL16tbFkyZK0fhnwBCN2fModPnzYOu9Xkvbu3auPPvpIL774okaNGvXQbRPWXwkPD9dXX30lFxcXLVy4UPPmzVPz5s119+5d5cqVy9r/tdde04YNGxQRESFnZ2e9/PLLWrdunSQpLi5Ohw8f1o0bNxQfH6+tW7fq+vXrat68uZycnFSpUiXlzJlTAwcO1LFjxxLVNnz4cOvIKQDPhwfPXwl+//13+fj4qH379pKS/nYv4bLnZ86cUZ8+fVSyZEktWbJEy5YtU8WKFeXg4GC9mEK2bNlUv359rVq1SpLk7e0tf39/rV27VtK9qcqHDx+WdG9UxM6dOxUfH69XXnlF7u7uKlu2rLJkyaKBAwfq8OHD6t+/v7WO69eva9q0aVyyGHgG3Lx5U/369bP+bRMTE6MVK1aoSpUqqlu3rvr27avjx48nuW3CxQ4kqU6dOsqXL5+io6PVuHFjeXp6qk+fPsqRI4eio6MVGxsrSfL19VWRIkWs04ELFCigvHnzWqfwbdy4UYMGDdKUKVPUtGlTrV69Wl27dpWLi4teeeUVrVq1SqdPn9bq1avVrFkzZc6c2Xq+DAgI0FtvvZWurxeAJ8eD5y/jvinHR44c0fjx4xUeHq5t27Yl2vb+81ezZs2sI0NfeeUV+fr6Kjg4WC4uLtY+klSoUCHlzp3ber4qUqSIsmTJYp3Ct3btWo0ZM0bTpk1TkyZNdPDgQXXt2lV2dnZq2rSpNm7cqHPnzumnn37Sq6++arOETGBgoFq3bp0OrxKeVIRST7FFixapU6dOku59aAsLC9OQIUN07Ngx3b59WydPntT169dttjEMQ3fv3rUZClmvXj25u7srICDA2q9FixayWCwKDQ21tjVv3lwnT57U6dOnJUkvv/yyTp06pStXrsje3l5jxoxRy5YtlStXLr311ltq0qSJatSoIUnq0qWLxowZo9dff10eHh4yDMPmZFm9enWuugc8Rx48f93v008/Vd26dWVnZ6cTJ05I+v+pyQ+ev5o1a6YcOXKoatWqku5dXa9t27Y6e/asIiMjrY/ZqFEj/fnnn7p48aKyZs2qKlWq6OjRo9Zwa+jQoWrUqJG8vb310UcfqWPHjtYpxf369dOECRP0xhtvJDp/JZw7Ey5nDODpFRISom3btql06dKS7k3HjYqKUp06dbRixQo5ODjozJkz1vvuZ2dnp8yZM0uSnJ2dVaRIEeXJk0e3b9+29qlWrZq2b99u0/bKK69o48aNku4F5hUqVNCyZcskST4+Ptq9e7cWLlwoPz8/zZs3z3redHZ2lpeXl6R7XwwaD6x5xYUXgOdLUuevhPPC7t27VaxYMfn7++vAgQOS7p2zEu6///yVcKX0hIu5SFKOHDlUrlw5bdq0ydqWPXt2ValSRWvWrJF0L1T38/PT+vXrJUmurq5avXq15syZowIFCmj27Nlq2rSppHvre+bOnVtS0ucv/qZ6/hBKPcXmzp2r9957z/qzq6urWrZsqa+//lqvv/66zp07p5MnT0r6/7Q8YTFzOzs7Xb16VbGxsfq/9u48KqrzfgP4MzM40yHDEkQ2URZRNlkqYowsUkNUQqNFMTEuAZtUjJAeY5qetol6tHLAaE04NS5JY44Jal2KC8FmcUGCBgQ0rkU57CBCCAcxBllm3t8f/O6VEbSpEiPM8/mPucvc4cBz5n7v933f4OBg2Nvbo76+Xj5XeHg42tra5O4BAPD19YW1tTUKCwvln9vb23HgwAEAwJw5cxAbG4usrCw0NDRg5cqVRqHS/Ubuf52fgYgGljvzS3Lx4kVYWFjg2WefhVarlZ+4if9fxUrKr+bmZgBdBW21Wm1UgI+OjkZjYyOuXLkiv/bEE09ApVKhsLAQCoUCXl5eaGhokLulZs2ahenTpyMrKwt1dXX4wx/+YFQsY34RDXytra2ora2Vb5YGDRqEX//611ixYgWmTZsGS0tLnD17Frdu3epx7LFjx5CQkICVK1cC6PoeVV1djdraWnmfmTNn4tSpU2hoaJBfi46OxqlTp1BdXQ2dToegoCC5CO/l5YVDhw4hNzcX7777LoKDg3u9bmnVZCIyXXfmF3C7eP7OO+9gzZo1GDFiBKqrq1FVVWW0PTs7Gy+//DI2bNgAoKtTqbCw0Oi7VVRUFLKzs+XFEzQaDZ5++mm5qO7k5AR3d3fcunULQghMmDABR44cQV5eHt59910EBQX1et3MLwJYlOqXpBujpqYmeVUCg8EAnU6HBQsWwMnJCeHh4bh+/TouXbpkdGxdXR1eeukljBo1CiNHjsTRo0fh5eUFOzs7lJSUoL29HUDXcBd3d3dcuHDBKJA8PT2xe/du/PDDD3BycsJ7770nd1g9/fTTWLhwofyl6c4hObyRI6K75ZeUF59++imsrKwQFxcHa2trZGdny8eWl5fjd7/7HUaOHIlRo0bhwoULGDduHLRaLYqLi6HX6wEAtra2GDZsGPLy8uRhMoMHD4ajoyP++c9/AujKsvXr12PkyJEAupZYf/XVV5lfRCasuLgYPj4+Rt97rKys5Ads48aNw9mzZ3Ht2jV5+7fffosXX3wRM2fORF1dndylEBkZibq6OvnhINBVgGpubpYnLgeA4OBgODk5oa6uDgqFAosWLUJRUZHcxWBmZiZn5J3dBEREkjvzS8qLw4cPw97eHt7e3vD29satW7dQXFwMALh8+TKioqLw3HPPoa6uDi4uLgC6CugXLlwwKqpPnToV1dXV8ogZ4PYKxuXl5VCr1UhOTsaBAwfk1UeZX/RjsSj1CBJCyDdXvVEoFKioqIC9vb08tle6WZL+4ceMGQONRiMXpaTtjY2NAIC//OUvKCgoQGRkJICurqfy8nKjoAkJCcHx48dRWVkpv5aSkoI33ngDWq0WZmZmeOWVV4zmguoeOFwpgcj03E9+AV15cf36dXz++eeYNWsWNBoNxo4dK8/folQqUVxcjM7OTrz55pvIz8+XV8AbPXo0vvnmGznfgK7hxRkZGXJHFQCkpqZi/vz5AABHR0csWbJELkpJ1979eoio/zMYDPfMJGkfAKioqIBGo5GL2RLp+MmTJ6O0tNToe5GNjQ3Wrl2Lq1ev4uDBg4iJiQHQ1Z2p0+nk3JL2VavVyM/Pl885ePBg1NTUYNy4cQC6ht1JnZndl2b/sasqE9HA8SD5Jb1+8OBBeHp6yvMBW1paYt++fcjIyICDgwO2bNmCyspKZGVl4dlnnwXQ9R1KoVDg4sWL8vv4+Pigo6MDX3/9tfzamDFjUF9fDzc3NwghoNFoekzRwvyiH4MDzh8h0hcQhUIBlUp1z311Oh1qamrk8b/SP7o0ftjGxgZubm4oKSnBtWvX5AnL/fz88OGHH8rnkYIuNDQUJ06cwLlz5+Dp6Qmg64lebW0trKys5P0jIiLuet3dr4OITMuD5JdUAKqpqYGZmRmmTJkCADA3N0dZWRlcXFywePFiLFmyBFFRUfJ5pPyaMmUKNm7cKBe7AGD27Nm4fv260bwqM2bMuOt1A8wvooFAeiov/e93LzBLiyt4eXkZHSPdQHl4eGD//v09zillWkREBFpbW3H58mVMnDhR3ibljkSv10OlUsHR0RGHDx9GXFycPKTm/PnzcHd37/W6pWtlFhGZpr7ML5VKherqapw+fRpr167F9u3bsXv3buTm5uLYsWM4efIkQkNDMXz4cKPzSfllb2+Pffv2YcaMGdBqtdBoNPjPf/4j3yd2vz7mFz0oPgr+mUjV6+6VZOmfuKCgAMuXL0dCQoLcXtmdEAK2tra4desWamtr5SF3d5577NixuHr1qtFEwXeSAiQoKAgGg0EeTgN0dUpt27ZNbuXs/v7dMXyITMtPlV8pKSloaGhAdHQ0bGxssHLlSrS1tcHZ2Rkvvvhij2KX9J7h4eFobGw0GnIzZcoUZGRk4PHHH+/x/r2dg4j6NymXpCEjkkuXLiE2NhY2NjaIiIjAxx9/jJs3bxodK2XL+PHjUVVVhW+//bbH+YUQGDJkCIYPH46zZ8/ixo0b//WaVqxYgeXLlxutZNxbQUq6biIyTT9lfknFp2XLlsHBwQHTpk1DUFAQduzYATs7ux7fi6SfN2zYgKSkJGi1Wnlb94JUd8wvelDslPqZdK8ml5WVQaPRwMLCAvHx8cjNzUVwcDC8vLzQ1NSEzs5Oo4DS6/UwMzNDUFAQ8vLy0NLSAltbW/mJv3TukJAQbN++HcXFxQgNDUVjY6O8UotEuiFzd3dHfn6+3LkgMRgMPeZS4U0ckWn7KfIL6BrukpeXBzc3NyQmJsLJyQnr1q1DR0cHHB0de3xxkq7D19cXlZWVPVZrYX4R9U/dOxh72yYtfNCdUqlER0cHmpqasGjRIgghkJ6ejvXr16O9vR2HDh3CsGHD8N133921mzMgIAA6nU6eb7P7NRgMBqhUKkRERCAnJweZmZmoq6uDu7s7YmJijDoFpPNL3VREZDoehfzy9PSEUqmEjY0NvvjiCzg5OcHV1RXm5ubIysrCypUrkZ+fD19fXznbJNJ3tujo6D76jRD9dyxrPoA7x8zeSa/X9zoOWAiBAwcOoLS0FAsWLICHhwcKCgrwwQcfoLa2FseOHUNWVhbWrFmD8ePH91jWVwq65557DleuXMGZM2d63e7i4oKOjg6kpaUhODgYgYGBRvOr3GnQoEG93vTxJo5o4HkU82vRokU4f/48NmzYgGeeeQaBgYFwcXFBdnY2bty4cc8sUqvVzC+ifqz7RLi9/d9KnQTdH75J9Ho93nvvPbi7u2Pbtm0YPHgw4uLi0NnZia1btyIpKQnjx4+HnZ0d/P398Ytf/KLH+fV6PZRKJWJiYnDw4MEeXeZNTU3YvHkzDh8+jJMnT2L+/PnYtm2bPF/U3ToFOLkv0cD3qOWXtMCCubk5IiMj4ePjI3c8jRo1CjY2NvIqeveacoH5RQ+LQvCvrU/cK4gAoLm5GdbW1gCAhoYGjB49GlqtFvPmzcMrr7wCZ2dn/PnPf0ZmZia2bt0KpVIJCwsLeHh43DUsWltbERMTg+HDh+P999832hYfH49du3YB6Oo+mDRpEqZPn46AgIB7VvCJyPQ8avklXZNCoUBOTg4qKysxc+ZMmJub980HJqJHVn19PXJyciCEQHh4uNHQN6BrOEt2djasra0xa9YsucN7586dWLRoEfz8/LBv3z65MzwsLAw3btyAo6MjPD09YW1tDX9/f8TExPTohFIqlcjLy8Obb76JiRMnYvny5fL8KoWFhZg6dSqmT5+OuLg4hIaGcsgKERl51PKrewdnd7wXpEeOoPvW2NgoZs+eLQoKCnpsa29vFzt27BBjx44VQ4YMEdOmTRMbN24UQgjR0dEhli5dKrRarcjJyZGPKS8vF1FRUUKj0YinnnpKhIeHC2dnZ5Gent7j/AaDQQghREZGhvD29hZZWVnyuYUQYufOneLTTz/t889MRAPDo5hfRGS6tm/fLgIDA4VWqxWhoaEiNjZWBAYGytuPHDkiwsPDxeOPPy7Cw8OFh4eHmDlzpigpKRFCCHH69Gnh7OwskpOThRBCtLW1CSGEuHTpkkhNTRV//etfxWuvvSZCQkKEh4eH+OSTT4QQt/NIotfrRUZGhrCwsBBlZWX3vGa9Xi/0en2f/Q6IqH/qr/lF9KjgnFI/UkdHB86dOwdXV1cMHjwYAGBpaYn8/Hz8+9//xqhRo7Bnzx54eXkhJCQEJ06cwLp16xAbG4vJkyfjq6++wsaNGyGEwOLFixEQEACDwQAfHx/5PVxdXbFz5060tbXhypUrMBgM2LlzJ9LS0vDLX/4SPj4+RitcAUBMTAzy8vKwbt06WFhYICwsDJ2dnZg9e7Z83u6T5xGR6elP+dXbUz3BJ3pEA9rnn3+O1atXIzY2FgcOHICzszPq6+tRX18vZ0J1dTWmTZuGzMxMWFpa4vLly1i4cCE2b96MdevWwdHREf7+/jh58iSA252f3t7e8Pb2Nno/Dw8PVFZWGu0nkYbAfPbZZ1i9ejXeeOMNeHl5yR2l3XOM36uIqL/kV2/7Ej0yfr56WP+SlpYmvL29xZkzZ4QQQty6dUuUl5cLGxsbodPphEKhEBMmTBA5OTmira1NzJ8/Xyxfvlw+vqysTISEhAg3Nzdx8+ZNceXKFaFWq8Xx48flfe6sdgshxMqVK0VwcLBcSe9O2v+7774Tf//738Xrr7/e63YiMm39Mb+IaOAzGAyio6NDeHl5iRkzZojW1tYeWSL93NDQIDo6OkRLS4vYu3evmDdvnlCpVMLf318I0ZVrKSkpYujQoUbHd3Z2ilOnTomamhpRX18v3n//feHv7y9OnTp112sSQojr16+LI0eOiNLS0r7+2EQ0ADC/iPoOS6R30Ov18qSVAOTlykNDQ2EwGLB06VI4ODjAz88PQgj4+vqira0N165dw4kTJxAWFga1Wo3MzEy0trbihRdegIODA8aMGQO1Wo2lS5dCoVDAwcEBPj4+yMzMBHB7lajCwkIsW7YMH330EebOnYsdO3YgLi4OHh4ePa5Vqnjb2NggKSkJy5Yt63U7EZmGgZRfRDTwKRQKHDp0CBUVFZg7d26vE/hKWTFkyBBcuHABkZGRWLVqFczNzbFixQqcP38e1dXV0Gg0CAgIwPfff4+LFy/Kx7e1tWHPnj2IioqCh4cHUlNTkZiYiMDAwLteE9DVTTpp0iS4u7v3/Qcnon6P+UXUd1iUuoNKpZJXi2puboZarUZHRwfeeecdlJeXo6qqCqmpqcjJyYGbmxt27doFtVqNoqIiAJBvCJ944gls2rQJw4cPx9atW1FSUoKjR48iKSkJWq0WOp0OkZGROHz4sNH7Ozg44NSpU9i0aRO0Wi02b96MxMTEH3XtVlZWffibIKL+hvlFRP2NWq1GW1sbbG1tAdz9gZoQAomJiRgxYgQOHTqELVu2YMqUKVAqlTh+/DgAwM3NDQ4ODtizZw+ArkwzNzfHnDlzkJKSgtLSUpSWlmLhwoXyBMNERPeL+UXUN0xqTqnOzk5UVlZixIgRd52j5Pjx41i/fj2++eYbuLq64oUXXkB8fDw++eQT6HQ61NXVYfLkyfJqChYWFggICMCBAwcQFRUFlUoFvV4PLy8vVFdXY82aNfK59Xo98vLy0NLSgqioKDz55JP429/+ZrSylbOzMw4ePAiNRvNQfidE1D8wv4hoIHJ0dIRKpUJ1dfU9549raWlBfX09YmNjMXToUABARkYGDAYDMjIyMG/ePNja2iI0NFRe6lwq0gcGBsqdBUIICCE4nwoRPTDmF1HfMJm/6M7OTsTHx+Oll16CXq/vNTQqKiqwZs0a2NjYID09HbNmzcKGDRuwYsUKAMCECRNQU1OD06dPy8c89thjmDRpEr788ksAkJcO/v3vf4/Gxkb85je/wYkTJ1BcXIy0tDQkJyejqakJQNcyn1u3bu1xA6fRaCCEgMFgkCfWJCLTxfwiooHKxcUFrq6u+OKLL9Dc3AwAPbLj6tWrsLKyQkREBJKTk/H2228jISEBNTU1WLVqlZxLtra2+Mc//oG33377ru/HCcqJqK8wv4j6hsn8VZuZmcmrDxQXFwO4HRrS6nSbNm2CwWDARx99hLCwMCQmJmLs2LHYvHkz6urq5HlZuo/1VSgU+NWvfoWKigpUVlbKVW13d3ds374der0eSUlJGDNmDNLT0zF16lRMnToVQNf44vj4eGi12h7XK4UO54UiIuYXEQ1U1tbWmDt3Lvbu3Yu9e/cCuJ1v7e3tWLVqFebPnw8ASE5Oxssvv4wdO3bg5s2bWLx4Md566y1kZ2cbnVPKRSKinxLzi6hvmNTwvcDAQGRlZaGgoAC+vr5ym6VSqURLSwsaGxuh0+mwbNky7Nq1C9euXYOTkxNeffVVDBo0CI6OjnB0dERZWRm+//576HQ6AF2TCLu4uGDJkiUYNmwYrl69ij/+8Y+IjIzEk08+iaqqKnh4eHD8LxHdN+YXEQ1UixcvxuXLl5GQkIAvv/wSM2bMQFVVFXJzc9Ha2orVq1cDAOzt7ZGcnIzU1FSj46XFFqRCODsJiOhhYX4RPTiTKkr5+fnBysoKRUVFiI+PN3qKb2lpidbWVhw9ehSdnZ146623EBYWBjc3N6NzjBs3Dvv378fx48cxevRoVFRUYOLEidi2bRs+/PBDlJSU4Pnnn4e/vz+EEHjsscfg7e0N4Hblm2FDRP8r5hcRDVR2dnbYvn07wsPDkZubi5SUFKjVasTExOD555/HiBEj5H1VKhWAruHGUkcmc4mIfi7ML6IHpxAmNulHQkICqqqqsHv3blhYWAC4PY/Kn/70Jxw7dgwff/wxPD09YTAYoFQq8fXXX6OpqQnR0dG4ePEi0tLSsH//fjQ2NmLOnDlIT0//mT8VEZkC5hcRDXStra29DgsmInrUMb+I7o/JlWZ9fHzQ3NyMc+fOAYDRCgYzZ86EVqtFfHw8jh49ioaGBvzrX/9CamoqvvrqKwCAr68v1q5di2PHjsFgMPS4oePkvkT0U2F+EdFAJoSQb+gMBgPnViGifoP5RXT/TK4oFRAQAKVSiaKiIvk1aRiMn58fNm3aBBsbG7z++uvw9vbGa6+9Bk9PT/z2t7+V97eysoKvry+Ari6F7ji5LxH9VJhfRDSQdc8fpVLJYS1E1G8wv4jun0nNKQV0dQrY2dnh/Pnz+OGHH1BUVITDhw/js88+g4+PD7Zs2YKsrCycOXMGjo6OcHBwuOf5pLHBREQ/NeYXERERERENJCY3pxTQtUrCBx98AI1Gg7a2NowePRpRUVFYsGABRo4cKc/FAnS1YkqrXLGDgIh+bswvIiIiIiIaKEyuUwoAnnnmGQwdOhTjx4/HU0891WN793ZL3swR0aOE+UVERERERAOFSXZK3YlLnRNRf8X8IiIiIiKi/spki1LSx2YXARH1N8wvIiIiIiIaCEy2KEVERERERERERD8fjvcgIiIiIiIiIqKHjkUpIiIiIiIiIiJ66FiUIiIiIiIiIiKih45FKSIiIiIiIiIieuhYlCIiIiIiIiIiooeORSkiIiIiIiIiInroWJQiIiIiIiIiIqKHjkUpIiIiIiIiIiJ66FiUIiIiIiIiIiKih+7/ABD7vdxZc733AAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "labels = list(results.keys())\n",
    "bitwise = [results[exp][\"bitwise\"] for exp in labels]\n",
    "missing = [results[exp][\"missing\"] for exp in labels]\n",
    "\n",
    "# Setup\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "bars2 = ax.bar(x + width/2, missing, width, label=\"Missing-bit Accuracy\", color='tab:red')\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    ax.text(x[i] + width/2, missing[i] + 0.005, f\"{missing[i]:.4f}\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Bit-wise Accuracy vs Missing-bit Accuracy per Esperimento\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=15)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-06T16:21:26.585642Z",
     "start_time": "2025-08-06T16:21:26.423596Z"
    }
   },
   "id": "9e51dad2e425a5b8",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-03T12:00:16.712572Z",
     "start_time": "2025-08-03T12:00:16.710531Z"
    }
   },
   "id": "6046ee766d49df01",
   "execution_count": 231
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
